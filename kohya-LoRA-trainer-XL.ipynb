{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timoshishi/diffusion/blob/main/kohya-LoRA-trainer-XL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slgjeYgd6pWp"
      },
      "source": [
        "[![visitor][visitor-badge]][visitor-stats]\n",
        "[![ko-fi][ko-fi-badge]][ko-fi-link]\n",
        "\n",
        "# **Kohya LoRA Trainer XL**\n",
        "A Colab Notebook For SDXL LoRA Training (Fine-tuning Method)\n",
        "\n",
        "[visitor-badge]: https://api.visitorbadge.io/api/visitors?path=Kohya%20LoRA%20Trainer%20XL&label=Visitors&labelColor=%2334495E&countColor=%231ABC9C&style=flat&labelStyle=none\n",
        "[visitor-stats]: https://visitorbadge.io/status?path=Kohya%20LoRA%20Trainer%20XL\n",
        "[ko-fi-badge]: https://img.shields.io/badge/Support%20me%20on%20Ko--fi-F16061?logo=ko-fi&logoColor=white&style=flat\n",
        "[ko-fi-link]: https://ko-fi.com/linaqruf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MxF9feWshAp"
      },
      "source": [
        "| Notebook Name | Description | Link |\n",
        "| --- | --- | --- |\n",
        "| [Kohya LoRA Trainer XL](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-trainer-XL.ipynb) | LoRA Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-trainer-XL.ipynb) |\n",
        "| [Kohya Trainer XL](https://github.com/Linaqruf/kohya-trainer/blob/main/kohya-trainer-XL.ipynb) | Native Training | [![](https://img.shields.io/static/v1?message=Open%20in%20Colab&logo=googlecolab&labelColor=5c5c5c&color=0f80c1&label=%20&style=flat)](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-trainer-XL.ipynb) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "<h4><font color=\"#4a90e2\"><b>NEWS:</b></font> <i>Colab's free-tier users can now train SDXL LoRA using the diffusers format instead of checkpoint as a pretrained model.</i></h4>\n",
        "<hr>"
      ],
      "metadata": {
        "id": "iIbwGFkJ0nTx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTVqCAgSmie4"
      },
      "source": [
        "# **I. Prepare Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "_u3q60di584x",
        "outputId": "e28ed7c7-05ef-4d94-dee2-4c0183d544ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/kohya-trainer'...\n",
            "remote: Enumerating objects: 2441, done.\u001b[K\n",
            "remote: Counting objects: 100% (1108/1108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (352/352), done.\u001b[K\n",
            "remote: Total 2441 (delta 859), reused 912 (delta 755), pack-reused 1333\u001b[K\n",
            "Receiving objects: 100% (2441/2441), 4.23 MiB | 9.90 MiB/s, done.\n",
            "Resolving deltas: 100% (1613/1613), done.\n",
            "Cloning into '/content/repositories/infinite-image-browsing'...\n",
            "remote: Enumerating objects: 7193, done.\u001b[K\n",
            "remote: Counting objects: 100% (1589/1589), done.\u001b[K\n",
            "remote: Compressing objects: 100% (429/429), done.\u001b[K\n",
            "remote: Total 7193 (delta 1245), reused 1416 (delta 1135), pack-reused 5604\u001b[K\n",
            "Receiving objects: 100% (7193/7193), 16.02 MiB | 19.05 MiB/s, done.\n",
            "Resolving deltas: 100% (5130/5130), done.\n",
            "Cloning into '/content/repositories/discordia-archivum'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 54 (delta 26), reused 21 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (54/54), 16.04 KiB | 16.04 MiB/s, done.\n",
            "Resolving deltas: 100% (26/26), done.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for discord-protos (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libaria2-0 libc-ares2\n",
            "The following NEW packages will be installed:\n",
            "  aria2 libaria2-0 libc-ares2 lz4\n",
            "0 upgraded, 4 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 1,603 kB of archives.\n",
            "After this operation, 5,676 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.2 [45.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaria2-0 amd64 1.36.0-1 [1,086 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 aria2 amd64 1.36.0-1 [381 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 lz4 amd64 1.9.3-2build2 [90.0 kB]\n",
            "Fetched 1,603 kB in 1s (2,167 kB/s)\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "(Reading database ... 120893 files and directories currently installed.)\n",
            "Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package libaria2-0:amd64.\n",
            "Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n",
            "Unpacking libaria2-0:amd64 (1.36.0-1) ...\n",
            "Selecting previously unselected package aria2.\n",
            "Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n",
            "Unpacking aria2 (1.36.0-1) ...\n",
            "Selecting previously unselected package lz4.\n",
            "Preparing to unpack .../lz4_1.9.3-2build2_amd64.deb ...\n",
            "Unpacking lz4 (1.9.3-2build2) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n",
            "Setting up lz4 (1.9.3-2build2) ...\n",
            "Setting up libaria2-0:amd64 (1.36.0-1) ...\n",
            "Setting up aria2 (1.36.0-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "--2023-09-04 16:24:30--  https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/669786276/620e2e64-be9f-4599-904f-18ee3811e159?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230904%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230904T162316Z&X-Amz-Expires=300&X-Amz-Signature=c4d03c52ec0db7ab13811bf8ee64c4a8e0a13aa4cce914d79475d6de07fa51d8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=669786276&response-content-disposition=attachment%3B%20filename%3Dlibtcmalloc_minimal.so.4&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-09-04 16:24:30--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/669786276/620e2e64-be9f-4599-904f-18ee3811e159?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230904%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230904T162316Z&X-Amz-Expires=300&X-Amz-Signature=c4d03c52ec0db7ab13811bf8ee64c4a8e0a13aa4cce914d79475d6de07fa51d8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=669786276&response-content-disposition=attachment%3B%20filename%3Dlibtcmalloc_minimal.so.4&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 373960 (365K) [application/octet-stream]\n",
            "Saving to: ‘/content/libtcmalloc_minimal.so.4’\n",
            "\n",
            "/content/libtcmallo 100%[===================>] 365.20K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-09-04 16:24:30 (15.0 MB/s) - ‘/content/libtcmalloc_minimal.so.4’ saved [373960/373960]\n",
            "\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m495.8/495.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.7/624.7 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/235.4 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.4/763.4 kB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.6/188.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for dadaptation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for contexttimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for elfinder-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.4/150.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title ## **1.1. Install Kohya Trainer**\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "import requests\n",
        "import torch\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive\n",
        "\n",
        "%store -r\n",
        "\n",
        "# root_dir\n",
        "root_dir          = \"/content\"\n",
        "drive_dir         = os.path.join(root_dir, \"drive/MyDrive\")\n",
        "deps_dir          = os.path.join(root_dir, \"deps\")\n",
        "repo_dir          = os.path.join(root_dir, \"kohya-trainer\")\n",
        "training_dir      = os.path.join(root_dir, \"LoRA\")\n",
        "pretrained_model  = os.path.join(root_dir, \"pretrained_model\")\n",
        "vae_dir           = os.path.join(root_dir, \"vae\")\n",
        "lora_dir          = os.path.join(root_dir, \"network_weight\")\n",
        "repositories_dir  = os.path.join(root_dir, \"repositories\")\n",
        "config_dir        = os.path.join(training_dir, \"config\")\n",
        "tools_dir         = os.path.join(repo_dir, \"tools\")\n",
        "finetune_dir      = os.path.join(repo_dir, \"finetune\")\n",
        "accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n",
        "\n",
        "for store in [\"root_dir\", \"repo_dir\", \"training_dir\", \"pretrained_model\", \"vae_dir\", \"repositories_dir\", \"accelerate_config\", \"tools_dir\", \"finetune_dir\", \"config_dir\"]:\n",
        "    with capture.capture_output() as cap:\n",
        "        %store {store}\n",
        "        del cap\n",
        "\n",
        "repo_dict = {\n",
        "    \"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\" : \"https://github.com/qaneel/kohya-trainer\",\n",
        "    \"kohya-ss/sd-scripts (original repo, latest update)\"                    : \"https://github.com/kohya-ss/sd-scripts\",\n",
        "}\n",
        "\n",
        "repository        = \"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\" #@param [\"qaneel/kohya-trainer (forked repo, stable, optimized for colab use)\", \"kohya-ss/sd-scripts (original repo, latest update)\"] {allow-input: true}\n",
        "repo_url          = repo_dict[repository]\n",
        "branch            = \"main\"  # @param {type: \"string\"}\n",
        "output_to_drive   = True  # @param {type: \"boolean\"}\n",
        "\n",
        "def clone_repo(url, dir, branch):\n",
        "    if not os.path.exists(dir):\n",
        "       !git clone -b {branch} {url} {dir}\n",
        "\n",
        "def mount_drive(dir):\n",
        "    output_dir      = os.path.join(training_dir, \"output\")\n",
        "\n",
        "    if output_to_drive:\n",
        "        if not os.path.exists(drive_dir):\n",
        "            drive.mount(os.path.dirname(drive_dir))\n",
        "        output_dir  = os.path.join(drive_dir, \"kohya-trainer/output\")\n",
        "\n",
        "    return output_dir\n",
        "\n",
        "def setup_directories():\n",
        "    global output_dir\n",
        "\n",
        "    output_dir      = mount_drive(drive_dir)\n",
        "\n",
        "    for dir in [training_dir, config_dir, pretrained_model, vae_dir, repositories_dir, output_dir]:\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "def pastebin_reader(id):\n",
        "    if \"pastebin.com\" in id:\n",
        "        url = id\n",
        "        if 'raw' not in url:\n",
        "                url = url.replace('pastebin.com', 'pastebin.com/raw')\n",
        "    else:\n",
        "        url = \"https://pastebin.com/raw/\" + id\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    lines = response.text.split('\\n')\n",
        "    return lines\n",
        "\n",
        "def install_repository():\n",
        "    global infinite_image_browser_dir, voldy, discordia_archivum_dir\n",
        "\n",
        "    _, voldy = pastebin_reader(\"kq6ZmHFU\")[:2]\n",
        "\n",
        "    infinite_image_browser_url  = f\"https://github.com/zanllp/{voldy}-infinite-image-browsing.git\"\n",
        "    infinite_image_browser_dir  = os.path.join(repositories_dir, f\"infinite-image-browsing\")\n",
        "    infinite_image_browser_deps = os.path.join(infinite_image_browser_dir, \"requirements.txt\")\n",
        "\n",
        "    discordia_archivum_url = \"https://github.com/Linaqruf/discordia-archivum\"\n",
        "    discordia_archivum_dir = os.path.join(repositories_dir, \"discordia-archivum\")\n",
        "    discordia_archivum_deps = os.path.join(discordia_archivum_dir, \"requirements.txt\")\n",
        "\n",
        "    clone_repo(infinite_image_browser_url, infinite_image_browser_dir, \"main\")\n",
        "    clone_repo(discordia_archivum_url, discordia_archivum_dir, \"main\")\n",
        "\n",
        "    !pip install -q --upgrade -r {infinite_image_browser_deps}\n",
        "    !pip install python-dotenv\n",
        "    !pip install -q --upgrade -r {discordia_archivum_deps}\n",
        "\n",
        "def install_dependencies():\n",
        "    requirements_file = os.path.join(repo_dir, \"requirements.txt\")\n",
        "    model_util        = os.path.join(repo_dir, \"library/model_util.py\")\n",
        "    gpu_info          = getoutput('nvidia-smi')\n",
        "    t4_xformers_wheel = \"https://github.com/Linaqruf/colab-xformers/releases/download/0.0.20/xformers-0.0.20+1d635e1.d20230519-cp310-cp310-linux_x86_64.whl\"\n",
        "\n",
        "    !apt install aria2 lz4\n",
        "    !wget https://github.com/camenduru/gperftools/releases/download/v1.0/libtcmalloc_minimal.so.4 -O /content/libtcmalloc_minimal.so.4\n",
        "    !pip install -q --upgrade -r {requirements_file}\n",
        "\n",
        "    if '2.0.1+cu118' in torch.__version__:\n",
        "        if 'T4' in gpu_info:\n",
        "            !pip install -q {t4_xformers_wheel}\n",
        "        else:\n",
        "            !pip install -q xformers==0.0.20\n",
        "    else:\n",
        "        !pip install -q torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 torchtext==0.15.1 torchdata==0.6.0 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "        !pip install -q xformers==0.0.19 triton==2.0.0 -U\n",
        "\n",
        "    from accelerate.utils import write_basic_config\n",
        "\n",
        "    if not os.path.exists(accelerate_config):\n",
        "        write_basic_config(save_location=accelerate_config)\n",
        "\n",
        "def prepare_environment():\n",
        "    os.environ[\"LD_PRELOAD\"] = \"/content/libtcmalloc_minimal.so.4\"\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "    os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "def main():\n",
        "    os.chdir(root_dir)\n",
        "    clone_repo(repo_url, repo_dir, branch)\n",
        "    os.chdir(repo_dir)\n",
        "    setup_directories()\n",
        "    install_repository()\n",
        "    install_dependencies()\n",
        "    prepare_environment()\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wrYGu-WxFbsq",
        "cellView": "form",
        "outputId": "398e1c8e-0a1a-4c4a-d163-ccad175f5601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempt to load diffusers model instead due to hardware constraints.\n",
            "Diffusers model is loaded : stabilityai/stable-diffusion-xl-base-1.0\n",
            "\n",
            "Starting downloading from https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl_vae.safetensors\n",
            "Download finished: /content/vae/sdxl_vae.safetensors\n",
            "\n",
            "Selected model: stabilityai/stable-diffusion-xl-base-1.0\n",
            "Selected VAE: /content/vae/sdxl_vae.safetensors\n"
          ]
        }
      ],
      "source": [
        "# @title ## **1.2. Download SDXL**\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import glob\n",
        "import gdown\n",
        "import requests\n",
        "import subprocess\n",
        "from IPython.utils import capture\n",
        "from urllib.parse import urlparse, unquote\n",
        "from pathlib import Path\n",
        "from huggingface_hub import HfFileSystem\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown Place your Huggingface token [here](https://huggingface.co/settings/tokens) to download gated models.\n",
        "\n",
        "HUGGINGFACE_TOKEN     = \"\" #@param {type: \"string\"}\n",
        "LOAD_DIFFUSERS_MODEL  = True #@param {type: \"boolean\"}\n",
        "SDXL_MODEL_URL        = \"stabilityai/stable-diffusion-xl-base-1.0\" # @param [\"gsdf/CounterfeitXL\", \"Linaqruf/animagine-xl\", \"stabilityai/stable-diffusion-xl-base-1.0\", \"PASTE MODEL URL OR GDRIVE PATH HERE\"] {allow-input: true}\n",
        "SDXL_VAE_URL          = \"FP16 VAE\" # @param [\"None\", \"Original VAE\", \"FP16 VAE\", \"PASTE VAE URL OR GDRIVE PATH HERE\"] {allow-input: true}\n",
        "\n",
        "MODEL_URLS = {\n",
        "    \"gsdf/CounterfeitXL\"        : \"https://huggingface.co/gsdf/CounterfeitXL/resolve/main/CounterfeitXL_%CE%B2.safetensors\",\n",
        "    \"Linaqruf/animagine-xl\"   : \"https://huggingface.co/Linaqruf/animagine-xl/resolve/main/animagine-xl.safetensors\",\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\" : \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\",\n",
        "}\n",
        "VAE_URLS = {\n",
        "    \"None\"                    : \"\",\n",
        "    \"Original VAE\"           : \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\",\n",
        "    \"FP16 VAE\"           : \"https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl_vae.safetensors\"\n",
        "}\n",
        "\n",
        "SDXL_MODEL_URL = MODEL_URLS.get(SDXL_MODEL_URL, SDXL_MODEL_URL)\n",
        "SDXL_VAE_URL = VAE_URLS.get(SDXL_VAE_URL, SDXL_VAE_URL)\n",
        "\n",
        "def get_filename(url):\n",
        "    if any(url.endswith(ext) for ext in [\".ckpt\", \".safetensors\", \".pt\", \".pth\"]):\n",
        "        return os.path.basename(url)\n",
        "\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    if 'content-disposition' in response.headers:\n",
        "        filename = re.findall('filename=\"?([^\"]+)\"?', response.headers['content-disposition'])[0]\n",
        "    else:\n",
        "        filename = unquote(os.path.basename(urlparse(url).path))\n",
        "\n",
        "    return filename\n",
        "\n",
        "def aria2_download(dir, filename, url):\n",
        "    user_header = f\"Authorization: Bearer {HUGGINGFACE_TOKEN}\"\n",
        "    aria2_args = [\n",
        "        \"aria2c\",\n",
        "        \"--console-log-level=error\",\n",
        "        \"--summary-interval=10\",\n",
        "        f\"--header={user_header}\" if \"huggingface.co\" in url else \"\",\n",
        "        \"--continue=true\",\n",
        "        \"--max-connection-per-server=16\",\n",
        "        \"--min-split-size=1M\",\n",
        "        \"--split=16\",\n",
        "        f\"--dir={dir}\",\n",
        "        f\"--out={filename}\",\n",
        "        url\n",
        "    ]\n",
        "    subprocess.run(aria2_args)\n",
        "\n",
        "def download(url, dst):\n",
        "    print(f\"Starting downloading from {url}\")\n",
        "    filename = get_filename(url)\n",
        "    filepath = os.path.join(dst, filename)\n",
        "\n",
        "    if \"drive.google.com\" in url:\n",
        "        gdown.download(url, filepath, quiet=False)\n",
        "    else:\n",
        "        if \"huggingface.co\" in url and \"/blob/\" in url:\n",
        "            url = url.replace(\"/blob/\", \"/resolve/\")\n",
        "        aria2_download(dst, filename, url)\n",
        "\n",
        "    print(f\"Download finished: {filepath}\")\n",
        "    return filepath\n",
        "\n",
        "def all_folders_present(base_model_url, sub_folders):\n",
        "    fs = HfFileSystem()\n",
        "    existing_folders = set(fs.ls(base_model_url, detail=False))\n",
        "\n",
        "    for folder in sub_folders:\n",
        "        full_folder_path = f\"{base_model_url}/{folder}\"\n",
        "        if full_folder_path not in existing_folders:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def get_total_ram_gb():\n",
        "    with open('/proc/meminfo', 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            if \"MemTotal\" in line:\n",
        "                return int(line.split()[1]) / (1024**2)  # Convert to GB\n",
        "\n",
        "def get_gpu_name():\n",
        "    try:\n",
        "        return subprocess.check_output(\"nvidia-smi --query-gpu=name --format=csv,noheader,nounits\", shell=True).decode('ascii').strip()\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    global model_path, vae_path, LOAD_DIFFUSERS_MODEL\n",
        "\n",
        "    model_path, vae_path = None, None\n",
        "\n",
        "    required_sub_folders = [\n",
        "        'scheduler',\n",
        "        'text_encoder',\n",
        "        'text_encoder_2',\n",
        "        'tokenizer',\n",
        "        'tokenizer_2',\n",
        "        'unet',\n",
        "        'vae',\n",
        "    ]\n",
        "\n",
        "    download_targets = {\n",
        "        \"model\": (SDXL_MODEL_URL, pretrained_model),\n",
        "        \"vae\": (SDXL_VAE_URL, vae_dir),\n",
        "    }\n",
        "\n",
        "    total_ram = get_total_ram_gb()\n",
        "    gpu_name = get_gpu_name()\n",
        "\n",
        "    # Check hardware constraints\n",
        "    if total_ram < 13 and gpu_name in [\"Tesla T4\", \"Tesla V100\"]:\n",
        "        print(\"Attempt to load diffusers model instead due to hardware constraints.\")\n",
        "        if not LOAD_DIFFUSERS_MODEL:\n",
        "            LOAD_DIFFUSERS_MODEL = True\n",
        "\n",
        "    for target, (url, dst) in download_targets.items():\n",
        "        if url and not url.startswith(f\"PASTE {target.upper()} URL OR GDRIVE PATH HERE\"):\n",
        "            if target == \"model\" and LOAD_DIFFUSERS_MODEL:\n",
        "                # Code for checking and handling diffusers model\n",
        "                if 'huggingface.co' in url:\n",
        "                    match = re.search(r'huggingface\\.co/([^/]+)/([^/]+)', SDXL_MODEL_URL)\n",
        "                    if match:\n",
        "                        username = match.group(1)\n",
        "                        model_name = match.group(2)\n",
        "                        url = f\"{username}/{model_name}\"\n",
        "                if all_folders_present(url, required_sub_folders):\n",
        "                    print(f\"Diffusers model is loaded : {url}\")\n",
        "                    model_path = url\n",
        "                else:\n",
        "                    print(\"Repository doesn't exist or no diffusers model detected.\")\n",
        "                    filepath = download(url, dst)  # Continue with the regular download\n",
        "                    model_path = filepath\n",
        "            else:\n",
        "                filepath = download(url, dst)\n",
        "\n",
        "                if target == \"model\":\n",
        "                    model_path = filepath\n",
        "                elif target == \"vae\":\n",
        "                    vae_path = filepath\n",
        "\n",
        "            print()\n",
        "\n",
        "    if model_path:\n",
        "        print(f\"Selected model: {model_path}\")\n",
        "\n",
        "    if vae_path:\n",
        "        print(f\"Selected VAE: {vae_path}\")\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_Wi3EkKt9MHi",
        "outputId": "00216dc1-7bb9-4df3-818e-284abc2e13e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kh7CeDqK4l3Y",
        "outputId": "925092d0-4552-4c45-de23-e5f6800c3542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 'train_data_dir' (str)\n",
            "Your train data directory : /content/drive/MyDrive/Lora/train_data\n"
          ]
        }
      ],
      "source": [
        "# @title ## **1.3. Directory Config**\n",
        "# @markdown Specify the location of your training data in the following cell. A folder with the same name as your input will be created.\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "train_data_dir = \"/content/drive/MyDrive/Lora/train_data\"  # @param {'type' : 'string'}\n",
        "%store train_data_dir\n",
        "\n",
        "os.makedirs(train_data_dir, exist_ok=True)\n",
        "print(f\"Your train data directory : {train_data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "id": "qqUYtRn0RPoK",
        "outputId": "a891d77c-1ada-4768-e189-35ee7c1d1e41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(46059, \"/\", \"100%\", 550, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title ## **1.4. Image Browser**\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import portpicker\n",
        "from IPython.utils import capture\n",
        "from IPython.display import clear_output\n",
        "from threading import Thread\n",
        "from imjoy_elfinder.app import main\n",
        "from google.colab.output import serve_kernel_port_as_iframe, serve_kernel_port_as_window\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown This cell allows you to view and manage your images in real-time. You can use it to:\n",
        "# @markdown - Prepare your dataset before training\n",
        "# @markdown - Monitor the sample outputs during training.\n",
        "\n",
        "root_dir      = \"/content\"\n",
        "browser_type  = \"infinite-image-browsing\" #@param [\"imjoy-elfinder\", \"infinite-image-browsing\"]\n",
        "window_height = 550 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
        "\n",
        "main_app          = os.path.join(infinite_image_browser_dir, \"app.py\")\n",
        "config_file       = os.path.join(infinite_image_browser_dir, \"config.json\")\n",
        "port              = portpicker.pick_unused_port()\n",
        "\n",
        "config = {\n",
        "    \"outdir_txt2img_samples\": train_data_dir,\n",
        "}\n",
        "\n",
        "def write_file(filename, config):\n",
        "    with open(filename, 'w',) as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "def run_app():\n",
        "    !python {main_app} --port={port} --sd_webui_config={config_file} > /dev/null 2>&1\n",
        "\n",
        "def launch():\n",
        "    os.chdir(root_dir)\n",
        "\n",
        "    thread = Thread(target=main, args=[[f\"--root-dir={root_dir}\",\n",
        "                                        f\"--port={port}\",\n",
        "                                        f\"--thumbnail\"]])\n",
        "\n",
        "    if browser_type == \"infinite-image-browsing\":\n",
        "        os.chdir(train_data_dir)\n",
        "        write_file(config_file, config)\n",
        "\n",
        "        thread = Thread(target=run_app)\n",
        "\n",
        "    thread.start()\n",
        "\n",
        "    serve_kernel_port_as_iframe(port, width='100%', height=window_height, cache_in_notebook=False)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En9UUwGNMRMM"
      },
      "source": [
        "# **II. Data Gathering**\n",
        "\n",
        "You have three options for collecting your dataset:\n",
        "\n",
        "1. Upload it to Colab's local files.\n",
        "2. Use the `Simple Booru Scraper` to download images in bulk from Danbooru.\n",
        "3. Locate your dataset in Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t17ZfiMB8GWZ"
      },
      "outputs": [],
      "source": [
        "# @title ## **2.1. Unzip Dataset**\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import re\n",
        "from urllib.parse import unquote\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# @title ## Unzip Dataset\n",
        "# @markdown If your dataset is in a `zip` file and has been uploaded to a location, use this section to extract it.\n",
        "# @markdown The dataset will be downloaded and automatically extracted to `train_data_dir` if `unzip_to` is empty.\n",
        "\n",
        "zipfile_url = \"/content/drive/MyDrive/Lora/train_data/3_t1m\"  # @param {type:\"string\"}\n",
        "unzip_to = \"\"  # @param {type:\"string\"}\n",
        "hf_token = \"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\"\n",
        "\n",
        "use_aria2c = True # @param {type:\"boolean\"}\n",
        "preserve_folders = True # @param {type:\"boolean\"}\n",
        "remove_after_unzipping = True # @param {type:\"boolean\"}\n",
        "\n",
        "if \"huggingface.co\" in zipfile_url and \"blob\" in zipfile_url:\n",
        "    zipfile_url = zipfile_url.replace(\"blob\", \"resolve\")\n",
        "\n",
        "if not unzip_to:\n",
        "    unzip_to = train_data_dir\n",
        "\n",
        "def get_filename_from_url(url):\n",
        "    if \"huggingface.co\" or \"/content/\" in url:\n",
        "        return os.path.basename(url)\n",
        "\n",
        "    response = requests.head(url, allow_redirects=True)\n",
        "    cd = response.headers.get('content-disposition')\n",
        "    if cd:\n",
        "        fname = re.findall('filename=(.+)', cd)\n",
        "        if len(fname) == 0:\n",
        "            return \"zipfile.zip\"\n",
        "        return unquote(fname[0])\n",
        "\n",
        "    return \"zipfile.zip\"\n",
        "\n",
        "def download_with_requests(url, output_path):\n",
        "    print(f\"Downloading {url} with requests...\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(output_path, 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "    print(f\"Downloaded to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def download_with_aria2c(url, output_path):\n",
        "    print(f\"Downloading {url} with aria2c...\")\n",
        "    aria_args = {\n",
        "        'console-log-level': 'error',\n",
        "        'summary-interval': '10',\n",
        "        'continue': 'true',\n",
        "        'max-connection-per-server': '16',\n",
        "        'min-split-size': '1M',\n",
        "        'split': '16',\n",
        "        'dir': os.path.dirname(output_path),\n",
        "        'out': os.path.basename(output_path),\n",
        "    }\n",
        "\n",
        "    if \"huggingface.co\" in url:\n",
        "        aria_args['header'] = f\"Authorization: Bearer {hf_token}\"\n",
        "\n",
        "    cmd = ['aria2c'] + [f'--{k}={v}' for k, v in aria_args.items()] + [url]\n",
        "    subprocess.run(cmd)\n",
        "    print(f\"Downloaded to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def move_files(train_dir):\n",
        "    for filename in os.listdir(train_dir):\n",
        "        file_path = os.path.join(train_dir, filename)\n",
        "        if filename.startswith(\"meta_\") and filename.endswith(\".json\"):\n",
        "            if not os.path.exists(file_path):\n",
        "                shutil.move(file_path, training_dir)\n",
        "            else:\n",
        "                os.remove(file_path)\n",
        "\n",
        "def remove_empty_dirs(path):\n",
        "    for dirpath, dirnames, files in os.walk(path, topdown=False):  # start from leaf folders\n",
        "        for dirname in dirnames:\n",
        "            full_dir_path = os.path.join(dirpath, dirname)\n",
        "            if not os.listdir(full_dir_path):  # Check if directory is empty\n",
        "                os.rmdir(full_dir_path)\n",
        "                print(f\"Removed empty directory: {full_dir_path}\")\n",
        "\n",
        "def extract_dataset(zip_file, output_path):\n",
        "    with ZipFile(zip_file, 'r') as zip_ref:\n",
        "        print(f\"Extracting {zip_file} to {output_path}...\")\n",
        "\n",
        "        if not preserve_folders:  # If we do not want to preserve folder structure\n",
        "            for member in zip_ref.namelist():\n",
        "                # Extract only the file name, discard directory structure\n",
        "                filename = os.path.basename(member)\n",
        "                if filename:  # Check if file name is not empty (this skips directories)\n",
        "                    zip_ref.extract(member, output_path)\n",
        "                    source_path = os.path.join(output_path, member)\n",
        "                    target_path = os.path.join(output_path, filename)\n",
        "                    os.rename(source_path, target_path)\n",
        "\n",
        "            remove_empty_dirs(output_path)\n",
        "\n",
        "        else:\n",
        "            zip_ref.extractall(output_path)\n",
        "\n",
        "        print(\"Extraction completed!\")\n",
        "\n",
        "def download_dataset(url, output_path):\n",
        "    if url.startswith(\"/content\"):\n",
        "        print(f\"Using file at {url}\")\n",
        "        return url\n",
        "\n",
        "    elif \"drive.google.com\" in url:\n",
        "        print(\"Downloading from Google Drive...\")\n",
        "        cmd = ['gdown', '--id', url.split('/')[-2], '-O', output_path]\n",
        "        subprocess.run(cmd)\n",
        "        return output_path\n",
        "\n",
        "    elif use_aria2c:\n",
        "        return download_with_aria2c(url, output_path)\n",
        "\n",
        "    else:\n",
        "        return download_with_requests(url, output_path)\n",
        "\n",
        "def main():\n",
        "    zipfile_name = get_filename_from_url(zipfile_url)\n",
        "    output_path = os.path.join(root_dir, zipfile_name)\n",
        "\n",
        "    zip_file = download_dataset(zipfile_url, output_path)\n",
        "\n",
        "    extract_dataset(zip_file, unzip_to)\n",
        "\n",
        "    move_files(unzip_to)\n",
        "\n",
        "    if remove_after_unzipping and \"/content/drive\" not in zip_file:\n",
        "        os.remove(zip_file)\n",
        "        print(f\"Removed {zip_file}\")\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "A0t1dfnU5Xkq"
      },
      "outputs": [],
      "source": [
        "#@title ## **2.2. Imageboard Scraper**\n",
        "import os\n",
        "import html\n",
        "from IPython.utils import capture\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "#@markdown Use `gallery-dl` to scrape images from an imageboard site. To specify `prompt(s)`, separate them with commas (e.g., `hito_komoru, touhou`).\n",
        "booru = \"Danbooru\" #@param [\"Danbooru\", \"Gelbooru\", \"Safebooru\"]\n",
        "prompt = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Alternatively, you can provide a `custom_url` instead of using a predefined site.\n",
        "custom_url = \"\" #@param {type: \"string\"}\n",
        "\n",
        "#@markdown Use the `sub_folder` option to organize the downloaded images into separate folders based on their concept or category.\n",
        "sub_folder = \"\" #@param {type: \"string\"}\n",
        "\n",
        "user_agent = \"gdl/1.24.5\"\n",
        "\n",
        "#@markdown You can limit the number of images to download by using the `--range` option followed by the desired range (e.g., `1-200`).\n",
        "range = \"\" #@param {type: \"string\"}\n",
        "\n",
        "write_tags = False #@param {type: \"boolean\"}\n",
        "\n",
        "additional_arguments = \"--filename /O --no-part\"\n",
        "\n",
        "tags = prompt.split(',')\n",
        "tags = '+'.join(tags)\n",
        "\n",
        "replacement_dict = {\" \": \"\", \"(\": \"%28\", \")\": \"%29\", \":\": \"%3a\"}\n",
        "tags = ''.join(replacement_dict.get(c, c) for c in tags)\n",
        "\n",
        "if sub_folder == \"\":\n",
        "    image_dir = train_data_dir\n",
        "elif sub_folder.startswith(\"/content\"):\n",
        "    image_dir = sub_folder\n",
        "else:\n",
        "    image_dir = os.path.join(train_data_dir, sub_folder)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "if booru == \"Danbooru\":\n",
        "    url = \"https://danbooru.donmai.us/posts?tags={}\".format(tags)\n",
        "elif booru == \"Gelbooru\":\n",
        "    url = \"https://gelbooru.com/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "else:\n",
        "    url = \"https://safebooru.org/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "\n",
        "valid_url = custom_url if custom_url else url\n",
        "\n",
        "def scrape(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "def pre_process_tags(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        item_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(item_path) and item.endswith(\".txt\"):\n",
        "            old_path = item_path\n",
        "            new_file_name = os.path.splitext(os.path.splitext(item)[0])[0] + \".txt\"\n",
        "            new_path = os.path.join(directory, new_file_name)\n",
        "\n",
        "            os.rename(old_path, new_path)\n",
        "\n",
        "            with open(new_path, \"r\") as f:\n",
        "                contents = f.read()\n",
        "\n",
        "            contents = html.unescape(contents)\n",
        "            contents = contents.replace(\"_\", \" \")\n",
        "            contents = \", \".join(contents.split(\"\\n\"))\n",
        "\n",
        "            with open(new_path, \"w\") as f:\n",
        "                f.write(contents)\n",
        "\n",
        "        elif os.path.isdir(item_path):\n",
        "            pre_process_tags(item_path)\n",
        "\n",
        "get_url_config = {\n",
        "    \"_valid_url\" : valid_url,\n",
        "    \"get-urls\" : True,\n",
        "    \"range\" : range if range else None,\n",
        "    \"user-agent\" : user_agent\n",
        "}\n",
        "\n",
        "scrape_config = {\n",
        "    \"_valid_url\" : valid_url,\n",
        "    \"directory\" : image_dir,\n",
        "    \"write-tags\" : write_tags,\n",
        "    \"range\" : range if range else None,\n",
        "    \"user-agent\" : user_agent\n",
        "}\n",
        "\n",
        "get_url_args = scrape(get_url_config)\n",
        "scrape_args = scrape(scrape_config)\n",
        "scraper_text = os.path.join(root_dir, \"scrape_this.txt\")\n",
        "\n",
        "if write_tags:\n",
        "    !gallery-dl {scrape_args} {additional_arguments}\n",
        "    pre_process_tags(train_data_dir)\n",
        "else:\n",
        "    with capture.capture_output() as cap:\n",
        "        !gallery-dl {get_url_args} {additional_arguments}\n",
        "    with open(scraper_text, \"w\") as f:\n",
        "        f.write(cap.stdout)\n",
        "\n",
        "    os.chdir(image_dir)\n",
        "    !aria2c --console-log-level=error --summary-interval=10 -c -x 16 -k 1M -s 16 -i {scraper_text}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EVWk3PM2KKB7"
      },
      "outputs": [],
      "source": [
        "#@title ## **2.3. Journey Scraper**\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "# @markdown Enter your Discord token below.\n",
        "token = \"\" #@param {type: \"string\"}\n",
        "channel_id = \"1022054094476673085\" #@param {type: \"string\"}\n",
        "# @markdown Which bot do you want to scrape? This code is optimized to only scrape non-grid images from the Journey bot, so don't worry about cropping.\n",
        "bot = \"niji\" #@param [\"niji\", \"mid\"]\n",
        "# @markdown Set the limit of messages to scrape here. (This does not limit the number of messages to download.)\n",
        "limit = 10000 #@param {type: \"number\"}\n",
        "# @markdown To specify the `include_word` and `undesired_word`, separate them with commas (e.g., hito_komoru, touhou). By default, it scrapes the newest Niji model.\n",
        "include_word = \"girl\" #@param {type:\"string\"}\n",
        "undesired_word = \"--style, --niji 4\" #@param {type:\"string\"}\n",
        "download_attachments = \"single\"\n",
        "\n",
        "def scrape(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "scrape_config = {\n",
        "    \"token\": token,\n",
        "    \"channel_id\": channel_id,\n",
        "    \"nijijourney\": True if bot == \"niji\" else False,\n",
        "    \"midjourney\": True if bot == \"mid\" else False,\n",
        "    \"limit\": limit if limit else None,\n",
        "    \"prompt\": include_word,\n",
        "    \"single\": True,\n",
        "    \"undesired_word\": undesired_word,\n",
        "    \"download_attachments\": True,\n",
        "    \"output_folder\": train_data_dir,\n",
        "\n",
        "}\n",
        "\n",
        "scrape_args = scrape(scrape_config)\n",
        "\n",
        "os.chdir(discordia_archivum_dir)\n",
        "!python main.py {scrape_args}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-0qKyEgTchp"
      },
      "source": [
        "# **III. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "Jz2emq6vWnPu",
        "outputId": "f1985e48-8ad9-46ef-bc40-412287b593f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Converted image: bees-0000-.png\n",
            " Converted image: hansel-0000-.png\n",
            " Converted image: truck-0000-.png\n",
            " Converted image: sweater-0000-.png\n",
            " Converted image: hat-0000-.png\n",
            " Converted image: legs-0000-.png\n",
            " Converted image: smoker-0000-.png\n",
            " Converted image: cooler-0000-.png\n",
            "All images have been converted\n"
          ]
        }
      ],
      "source": [
        "# @title ## **3.1. Data Cleaning**\n",
        "import os\n",
        "import random\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "test = os.listdir(train_data_dir)\n",
        "#@markdown This section removes unsupported media types such as `.mp4`, `.webm`, and `.gif`, as well as any unnecessary files.\n",
        "#@markdown To convert a transparent dataset with an alpha channel (RGBA) to RGB and give it a white background, set the `convert` parameter to `True`.\n",
        "convert = True  # @param {type:\"boolean\"}\n",
        "#@markdown Alternatively, you can give the background a `random_color` instead of white by checking the corresponding option.\n",
        "random_color = True  # @param {type:\"boolean\"}\n",
        "recursive = False\n",
        "\n",
        "batch_size = 32\n",
        "supported_types = [\n",
        "    \".png\",\n",
        "    \".jpg\",\n",
        "    \".jpeg\",\n",
        "    \".webp\",\n",
        "    \".bmp\",\n",
        "    \".caption\",\n",
        "    \".npz\",\n",
        "    \".txt\",\n",
        "    \".json\",\n",
        "]\n",
        "\n",
        "background_colors = [\n",
        "    (255, 255, 255),\n",
        "    (0, 0, 0),\n",
        "    (255, 0, 0),\n",
        "    (0, 255, 0),\n",
        "    (0, 0, 255),\n",
        "    (255, 255, 0),\n",
        "    (255, 0, 255),\n",
        "    (0, 255, 255),\n",
        "]\n",
        "\n",
        "def clean_directory(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(file_path):\n",
        "            file_ext = os.path.splitext(item)[1]\n",
        "            if file_ext not in supported_types:\n",
        "                print(f\"Deleting file {item} from {directory}\")\n",
        "                os.remove(file_path)\n",
        "        elif os.path.isdir(file_path) and recursive:\n",
        "            clean_directory(file_path)\n",
        "\n",
        "def process_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img_dir, image_name = os.path.split(image_path)\n",
        "\n",
        "    if img.mode in (\"RGBA\", \"LA\"):\n",
        "        if random_color:\n",
        "            background_color = random.choice(background_colors)\n",
        "        else:\n",
        "            background_color = (255, 255, 255)\n",
        "        bg = Image.new(\"RGB\", img.size, background_color)\n",
        "        bg.paste(img, mask=img.split()[-1])\n",
        "\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            bg = bg.convert(\"RGB\")\n",
        "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
        "            bg.save(new_image_path, \"JPEG\")\n",
        "            os.remove(image_path)\n",
        "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
        "        else:\n",
        "            bg.save(image_path, \"PNG\")\n",
        "            print(f\" Converted image: {image_name}\")\n",
        "    else:\n",
        "        if image_name.endswith(\".webp\"):\n",
        "            new_image_path = os.path.join(img_dir, image_name.replace(\".webp\", \".jpg\"))\n",
        "            img.save(new_image_path, \"JPEG\")\n",
        "            os.remove(image_path)\n",
        "            print(f\" Converted image: {image_name} to {os.path.basename(new_image_path)}\")\n",
        "        else:\n",
        "            img.save(image_path, \"PNG\")\n",
        "\n",
        "def find_images(directory):\n",
        "    images = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(\".png\") or file.endswith(\".webp\"):\n",
        "                images.append(os.path.join(root, file))\n",
        "    return images\n",
        "\n",
        "clean_directory(train_data_dir)\n",
        "images = find_images(train_data_dir)\n",
        "num_batches = len(images) // batch_size + 1\n",
        "\n",
        "if convert:\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        for i in tqdm(range(num_batches)):\n",
        "            start = i * batch_size\n",
        "            end = start + batch_size\n",
        "            batch = images[start:end]\n",
        "            executor.map(process_image, batch)\n",
        "\n",
        "    print(\"All images have been converted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdISafLeyklg"
      },
      "source": [
        "## **3.2. Data Captioning**\n",
        "\n",
        "- For general images, use BLIP captioning.\n",
        "- For anime and manga-style images, use Waifu Diffusion 1.4 Tagger V2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "id": "nvPyH-G_Qdha",
        "outputId": "4e901dad-5452-4501-8c1d-cbb3100822ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load images from /content/drive/MyDrive/Lora/train_data\n",
            "found 15 images.\n",
            "loading BLIP caption: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 1.80MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 158kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 3.18MB/s]\n",
            "100% 1.66G/1.66G [00:07<00:00, 232MB/s]\n",
            "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "BLIP loaded\n",
            "  0% 0/2 [00:00<?, ?it/s]/content/drive/MyDrive/Lora/train_data/3_t1m/20230803_161654-0000-.jpg a man standing in a living room with a chandelier\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/bees-0000-.jpg a man standing next to a white dog\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/bees-0000-.png a man standing next to a white dog\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/cooler-0000-.png a man is holding out his hand to someone\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/cside.jpg a man standing in a room with a remote in his hand\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/eyes.jpg a man is looking at his cell phone\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/frontal.jpg a man in a white shirt is looking at the camera\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/full.jpg a man standing in a living room next to a dining room table\n",
            "100% 2/2 [00:13<00:00,  6.94s/it]\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/hansel-0000-.png a man in a black jacket is smiling\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/hat-0000-.png a man wearing a hat with a blue visor\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/legs-0000-.png a man in shorts and a white shirt is holding a white shirt\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/smoker-0000-.png a man in a black and orange jacket pointing at something\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/sweater-0000-.png a man in a gray hoodie is looking at the camera\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/truck-0000-.png a man and a woman standing next to each other\n",
            "/content/drive/MyDrive/Lora/train_data/3_t1m/viewer.jpg a man in a shirt and tie standing in a room\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "#@title ### **3.2.1. BLIP Captioning**\n",
        "#@markdown BLIP is a pre-training framework for unified vision-language understanding and generation, which achieves state-of-the-art results on a wide range of vision-language tasks. It can be used as a tool for image captioning, for example, `astronaut riding a horse in space`.\n",
        "import os\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "beam_search = True #@param {type:'boolean'}\n",
        "min_length = 5 #@param {type:\"slider\", min:0, max:100, step:5.0}\n",
        "max_length = 75 #@param {type:\"slider\", min:0, max:100, step:5.0}\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\"   : train_data_dir,\n",
        "    \"batch_size\"        : 8,\n",
        "    \"beam_search\"       : beam_search,\n",
        "    \"min_length\"        : min_length,\n",
        "    \"max_length\"        : max_length,\n",
        "    \"debug\"             : True,\n",
        "    \"caption_extension\" : \".caption\",\n",
        "    \"max_data_loader_n_workers\" : 2,\n",
        "    \"recursive\"         : True\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python make_captions.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-BdXV7rAy2ag"
      },
      "outputs": [],
      "source": [
        "#@title ### **3.2.2. Waifu Diffusion 1.4 Tagger V2**\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "\n",
        "#@markdown [Waifu Diffusion 1.4 Tagger V2](https://huggingface.co/spaces/SmilingWolf/wd-v1-4-tags) is a Danbooru-styled image classification model developed by SmilingWolf. It can also be useful for general image tagging, for example, `1girl, solo, looking_at_viewer, short_hair, bangs, simple_background`.\n",
        "model = \"SmilingWolf/wd-v1-4-moat-tagger-v2\" #@param [\"SmilingWolf/wd-v1-4-moat-tagger-v2\", \"SmilingWolf/wd-v1-4-convnextv2-tagger-v2\", \"SmilingWolf/wd-v1-4-swinv2-tagger-v2\", \"SmilingWolf/wd-v1-4-convnext-tagger-v2\", \"SmilingWolf/wd-v1-4-vit-tagger-v2\"]\n",
        "#@markdown Separate `undesired_tags` with comma `(,)` if you want to remove multiple tags, e.g. `1girl,solo,smile`.\n",
        "undesired_tags = \"\" #@param {type:'string'}\n",
        "#@markdown Adjust `general_threshold` for pruning tags (less tags, less flexible). `character_threshold` is useful if you want to train with character tags, e.g. `hakurei reimu`.\n",
        "general_threshold = 0.35 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "character_threshold = 0.85 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "\n",
        "config = {\n",
        "    \"_train_data_dir\"           : train_data_dir,\n",
        "    \"batch_size\"                : 8,\n",
        "    \"repo_id\"                   : model,\n",
        "    \"recursive\"                 : True,\n",
        "    \"remove_underscore\"         : True,\n",
        "    \"general_threshold\"         : general_threshold,\n",
        "    \"character_threshold\"       : character_threshold,\n",
        "    \"caption_extension\"         : \".txt\",\n",
        "    \"max_data_loader_n_workers\" : 2,\n",
        "    \"debug\"                     : True,\n",
        "    \"undesired_tags\"            : undesired_tags\n",
        "}\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python tag_images_by_wd14_tagger.py {args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cellView": "form",
        "id": "_mLVURhM9PFE"
      },
      "outputs": [],
      "source": [
        "# @title ### **3.2.3. Custom Caption/Tag**\n",
        "import os\n",
        "\n",
        "%store -r\n",
        "\n",
        "os.chdir(root_dir)\n",
        "\n",
        "# @markdown Add or remove custom tags here.\n",
        "extension   = \".caption\"  # @param [\".txt\", \".caption\"]\n",
        "custom_tag  = \"a man\"  # @param {type:\"string\"}\n",
        "# @markdown Use `sub_folder` option to specify a subfolder for multi-concept training.\n",
        "# @markdown > Specify `--all` to process all subfolders/`recursive`\n",
        "sub_folder  = \"/content/drive/MyDrive/Lora/train_data/3_t1m\" #@param {type: \"string\"}\n",
        "# @markdown Enable this to append custom tags at the end of lines.\n",
        "append      = False  # @param {type:\"boolean\"}\n",
        "# @markdown Enable this if you want to remove captions/tags instead.\n",
        "remove_tag  = True  # @param {type:\"boolean\"}\n",
        "recursive   = False\n",
        "\n",
        "if sub_folder == \"\":\n",
        "    image_dir = train_data_dir\n",
        "elif sub_folder == \"--all\":\n",
        "    image_dir = train_data_dir\n",
        "    recursive = True\n",
        "elif sub_folder.startswith(\"/content\"):\n",
        "    image_dir = sub_folder\n",
        "else:\n",
        "    image_dir = os.path.join(train_data_dir, sub_folder)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def process_tags(filename, custom_tag, append, remove_tag):\n",
        "    contents = read_file(filename)\n",
        "    tags = [tag.strip() for tag in contents.split(',')]\n",
        "    custom_tags = [tag.strip() for tag in custom_tag.split(',')]\n",
        "\n",
        "    for custom_tag in custom_tags:\n",
        "        custom_tag = custom_tag.replace(\"_\", \" \")\n",
        "        if remove_tag:\n",
        "            while custom_tag in tags:\n",
        "                tags.remove(custom_tag)\n",
        "        else:\n",
        "            if custom_tag not in tags:\n",
        "                if append:\n",
        "                    tags.append(custom_tag)\n",
        "                else:\n",
        "                    tags.insert(0, custom_tag)\n",
        "\n",
        "    contents = ', '.join(tags)\n",
        "    write_file(filename, contents)\n",
        "\n",
        "def process_directory(image_dir, tag, append, remove_tag, recursive):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "\n",
        "        if os.path.isdir(file_path) and recursive:\n",
        "            process_directory(file_path, tag, append, remove_tag, recursive)\n",
        "        elif filename.endswith(extension):\n",
        "            process_tags(file_path, tag, append, remove_tag)\n",
        "\n",
        "tag = custom_tag\n",
        "\n",
        "if not any(\n",
        "    [filename.endswith(extension) for filename in os.listdir(image_dir)]\n",
        "):\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")):\n",
        "            open(\n",
        "                os.path.join(image_dir, filename.split(\".\")[0] + extension),\n",
        "                \"w\",\n",
        "            ).close()\n",
        "\n",
        "if custom_tag:\n",
        "    process_directory(image_dir, tag, append, remove_tag, recursive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cellView": "form",
        "id": "hhgatqF3leHJ",
        "outputId": "f2670d19-e4b1-4050-d893-1a3cb740984e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15 images.\n",
            "Creating a new metadata file\n",
            "Merging tags and captions into metadata json.\n",
            "100% 15/15 [00:04<00:00,  3.64it/s]\n",
            "All 15 images have captions\n",
            "No tags found for any of the 15 images\n",
            "Cleaning captions and tags.\n",
            "100% 15/15 [00:00<00:00, 74455.10it/s]\n",
            "Writing metadata: /content/LoRA/meta_clean.json\n",
            "Done!\n",
            "found 15 images.\n",
            "loading existing metadata: /content/LoRA/meta_clean.json\n",
            "load VAE: /content/vae/sdxl_vae.safetensors\n",
            "100% 15/15 [00:13<00:00,  1.12it/s]\n",
            "bucket 0 (320, 1024): 1\n",
            "bucket 1 (384, 1024): 3\n",
            "bucket 2 (768, 1024): 5\n",
            "bucket 3 (1024, 1024): 6\n",
            "mean ar error: 0.006040597948380829\n",
            "writing metadata: /content/LoRA/meta_lat.json\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "# @title ## **3.4. Bucketing and Latents Caching**\n",
        "%store -r\n",
        "\n",
        "# @markdown This code will create buckets based on the `bucket_resolution` provided for multi-aspect ratio training, and then convert all images within the `train_data_dir` to latents.\n",
        "bucketing_json    = os.path.join(training_dir, \"meta_lat.json\")\n",
        "metadata_json     = os.path.join(training_dir, \"meta_clean.json\")\n",
        "bucket_resolution = 1024  # @param {type:\"slider\", min:512, max:1024, step:128}\n",
        "mixed_precision   = \"no\"  # @param [\"no\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "skip_existing     = False  # @param{type:\"boolean\"}\n",
        "flip_aug          = False  # @param{type:\"boolean\"}\n",
        "# @markdown Use `clean_caption` option to clean such as duplicate tags, `women` to `girl`, etc\n",
        "clean_caption     = True #@param {type:\"boolean\"}\n",
        "#@markdown Use the `recursive` option to process subfolders as well\n",
        "recursive         = True #@param {type:\"boolean\"}\n",
        "\n",
        "metadata_config = {\n",
        "    \"_train_data_dir\": train_data_dir,\n",
        "    \"_out_json\": metadata_json,\n",
        "    \"recursive\": recursive,\n",
        "    \"full_path\": recursive,\n",
        "    \"clean_caption\": clean_caption\n",
        "}\n",
        "\n",
        "bucketing_config = {\n",
        "    \"_train_data_dir\": train_data_dir,\n",
        "    \"_in_json\": metadata_json,\n",
        "    \"_out_json\": bucketing_json,\n",
        "    \"_model_name_or_path\": vae_path if vae_path else model_path,\n",
        "    \"recursive\": recursive,\n",
        "    \"full_path\": recursive,\n",
        "    \"flip_aug\": flip_aug,\n",
        "    \"skip_existing\": skip_existing,\n",
        "    \"batch_size\": 4,\n",
        "    \"max_data_loader_n_workers\": 2,\n",
        "    \"max_resolution\": f\"{bucket_resolution}, {bucket_resolution}\",\n",
        "    \"mixed_precision\": mixed_precision,\n",
        "}\n",
        "\n",
        "def generate_args(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "    return args.strip()\n",
        "\n",
        "merge_metadata_args = generate_args(metadata_config)\n",
        "prepare_buckets_args = generate_args(bucketing_config)\n",
        "\n",
        "merge_metadata_command = f\"python merge_all_to_metadata.py {merge_metadata_args}\"\n",
        "prepare_buckets_command = f\"python prepare_buckets_latents.py {prepare_buckets_args}\"\n",
        "\n",
        "os.chdir(finetune_dir)\n",
        "!{merge_metadata_command}\n",
        "time.sleep(1)\n",
        "!{prepare_buckets_command}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAZVkLuaRJ9e"
      },
      "source": [
        "# **IV. Training**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cJgLfRtlHSjw",
        "outputId": "864e09fe-d7ed-43eb-e269-15e9654f6ac1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 32\n",
            "network_alpha = 16\n",
            "network_args = []\n",
            "network_train_unet_only = true\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import toml\n",
        "\n",
        "# @title ## **4.1. LoRa: Low-Rank Adaptation Config**\n",
        "# @markdown Kohya's `LoRA` renamed to `LoRA-LierLa` and Kohya's `LoCon` renamed to `LoRA-C3Lier`, read [official announcement](https://github.com/kohya-ss/sd-scripts/blob/849bc24d205a35fbe1b2a4063edd7172533c1c01/README.md#naming-of-lora).\n",
        "network_category = \"LoRA_LierLa\"  # @param [\"LoRA_LierLa\", \"LoRA_C3Lier\", \"DyLoRA_LierLa\", \"DyLoRA_C3Lier\", \"LoCon\", \"LoHa\", \"IA3\", \"LoKR\", \"DyLoRA_Lycoris\"]\n",
        "\n",
        "# @markdown | network_category | network_dim | network_alpha | conv_dim | conv_alpha | unit |\n",
        "# @markdown | :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "# @markdown | LoRA-LierLa | 32 | 1 | - | - | - |\n",
        "# @markdown | LoCon/LoRA-C3Lier | 16 | 8 | 8 | 1 | - |\n",
        "# @markdown | LoHa | 8 | 4 | 4 | 1 | - |\n",
        "# @markdown | Other Category | ? | ? | ? | ? | - |\n",
        "\n",
        "# @markdown Specify `network_args` to add `optional` training args, like for specifying each 25 block weight, read [this](https://github.com/kohya-ss/sd-scripts/blob/main/train_network_README-ja.md#%E9%9A%8E%E5%B1%A4%E5%88%A5%E5%AD%A6%E7%BF%92%E7%8E%87)\n",
        "network_args    = \"\"  # @param {'type':'string'}\n",
        "\n",
        "# @markdown ### **Linear Layer Config**\n",
        "# @markdown Used by all `network_category`. When in doubt, set `network_dim = network_alpha`\n",
        "network_dim     = 32  # @param {'type':'number'}\n",
        "network_alpha   = 16  # @param {'type':'number'}\n",
        "\n",
        "# @markdown ### **Convolutional Layer Config**\n",
        "# @markdown Only required if `network_category` is not `LoRA_LierLa`, as it involves training convolutional layers in addition to linear layers.\n",
        "conv_dim        = 32  # @param {'type':'number'}\n",
        "conv_alpha      = 16  # @param {'type':'number'}\n",
        "\n",
        "# @markdown ### **DyLoRA Config**\n",
        "# @markdown Only required if `network_category` is `DyLoRA_LierLa` and `DyLoRA_C3Lier`\n",
        "unit = 4  # @param {'type':'number'}\n",
        "\n",
        "if isinstance(network_args, str):\n",
        "    network_args = network_args.strip()\n",
        "    if network_args.startswith('[') and network_args.endswith(']'):\n",
        "        try:\n",
        "            network_args = ast.literal_eval(network_args)\n",
        "        except (SyntaxError, ValueError) as e:\n",
        "            print(f\"Error parsing network_args: {e}\\n\")\n",
        "            network_args = []\n",
        "    elif len(network_args) > 0:\n",
        "        print(f\"WARNING! '{network_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
        "        network_args = []\n",
        "    else:\n",
        "        network_args = []\n",
        "else:\n",
        "    network_args = []\n",
        "\n",
        "network_config = {\n",
        "    \"LoRA_LierLa\": {\n",
        "        \"module\": \"networks.lora\",\n",
        "        \"args\"  : []\n",
        "    },\n",
        "    \"LoRA_C3Lier\": {\n",
        "        \"module\": \"networks.lora\",\n",
        "        \"args\"  : [\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_LierLa\": {\n",
        "        \"module\": \"networks.dylora\",\n",
        "        \"args\"  : [\n",
        "            f\"unit={unit}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_C3Lier\": {\n",
        "        \"module\": \"networks.dylora\",\n",
        "        \"args\"  : [\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\",\n",
        "            f\"unit={unit}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoCon\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=locon\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoHa\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=loha\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"IA3\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=ia3\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"LoKR\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=lokr\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    },\n",
        "    \"DyLoRA_Lycoris\": {\n",
        "        \"module\": \"lycoris.kohya\",\n",
        "        \"args\"  : [\n",
        "            f\"algo=dylora\",\n",
        "            f\"conv_dim={conv_dim}\",\n",
        "            f\"conv_alpha={conv_alpha}\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "network_module = network_config[network_category][\"module\"]\n",
        "network_args.extend(network_config[network_category][\"args\"])\n",
        "\n",
        "lora_config = {\n",
        "    \"additional_network_arguments\": {\n",
        "        \"no_metadata\"                     : False,\n",
        "        \"network_module\"                  : network_module,\n",
        "        \"network_dim\"                     : network_dim,\n",
        "        \"network_alpha\"                   : network_alpha,\n",
        "        \"network_args\"                    : network_args,\n",
        "        \"network_train_unet_only\"         : True,\n",
        "        \"training_comment\"                : None,\n",
        "    },\n",
        "}\n",
        "\n",
        "print(toml.dumps(lora_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "cellView": "form",
        "id": "JNlw3u8arwir",
        "outputId": "e5e302f0-3052-4b77-e48a-0dbbf5527dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdaFactor\"\n",
            "learning_rate = 0.0001\n",
            "max_grad_norm = 0\n",
            "optimizer_args = [ \"scale_parameter=False\", \"relative_step=False\", \"warmup_init=False\",]\n",
            "lr_scheduler = \"constant_with_warmup\"\n",
            "lr_warmup_steps = 100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import toml\n",
        "import ast\n",
        "\n",
        "# @title ## **4.2. Optimizer Config**\n",
        "# @markdown Use `Adafactor` optimizer. `RMSprop 8bit` or `Adagrad 8bit` may work. `AdamW 8bit` doesn't seem to work.\n",
        "optimizer_type = \"AdaFactor\"  # @param [\"AdamW\", \"AdamW8bit\", \"Lion8bit\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"DAdaptation(DAdaptAdamPreprint)\", \"DAdaptAdaGrad\", \"DAdaptAdam\", \"DAdaptAdan\", \"DAdaptAdanIP\", \"DAdaptLion\", \"DAdaptSGD\", \"AdaFactor\"]\n",
        "# @markdown Specify `optimizer_args` to add `additional` args for optimizer, e.g: `[\"weight_decay=0.6\"]`\n",
        "optimizer_args = \"[ \\\"scale_parameter=False\\\", \\\"relative_step=False\\\", \\\"warmup_init=False\\\" ]\"  # @param {'type':'string'}\n",
        "# @markdown ### **Learning Rate Config**\n",
        "# @markdown Different `optimizer_type` and `network_category` for some condition requires different learning rate. It's recommended to set `text_encoder_lr = 1/2 * unet_lr`\n",
        "learning_rate = 1e-4  # @param {'type':'number'}\n",
        "# @markdown ### **LR Scheduler Config**\n",
        "# @markdown `lr_scheduler` provides several methods to adjust the learning rate based on the number of epochs.\n",
        "lr_scheduler = \"constant_with_warmup\"  # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"adafactor\"] {allow-input: false}\n",
        "lr_warmup_steps = 100  # @param {'type':'number'}\n",
        "# @markdown Specify `lr_scheduler_num` with `num_cycles` value for `cosine_with_restarts` or `power` value for `polynomial`\n",
        "lr_scheduler_num = 0  # @param {'type':'number'}\n",
        "\n",
        "if isinstance(optimizer_args, str):\n",
        "    optimizer_args = optimizer_args.strip()\n",
        "    if optimizer_args.startswith('[') and optimizer_args.endswith(']'):\n",
        "        try:\n",
        "            optimizer_args = ast.literal_eval(optimizer_args)\n",
        "        except (SyntaxError, ValueError) as e:\n",
        "            print(f\"Error parsing optimizer_args: {e}\\n\")\n",
        "            optimizer_args = []\n",
        "    elif len(optimizer_args) > 0:\n",
        "        print(f\"WARNING! '{optimizer_args}' is not a valid list! Put args like this: [\\\"args=1\\\", \\\"args=2\\\"]\\n\")\n",
        "        optimizer_args = []\n",
        "    else:\n",
        "        optimizer_args = []\n",
        "else:\n",
        "    optimizer_args = []\n",
        "\n",
        "optimizer_config = {\n",
        "    \"optimizer_arguments\": {\n",
        "        \"optimizer_type\"          : optimizer_type,\n",
        "        \"learning_rate\"           : learning_rate,\n",
        "        \"max_grad_norm\"           : 0,\n",
        "        \"optimizer_args\"          : optimizer_args,\n",
        "        \"lr_scheduler\"            : lr_scheduler,\n",
        "        \"lr_warmup_steps\"         : lr_warmup_steps,\n",
        "        \"lr_scheduler_num_cycles\" : lr_scheduler_num if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\"      : lr_scheduler_num if lr_scheduler == \"polynomial\" else None,\n",
        "        \"lr_scheduler_type\"       : None,\n",
        "        \"lr_scheduler_args\"       : None,\n",
        "    },\n",
        "}\n",
        "\n",
        "print(toml.dumps(optimizer_config))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YOxNM0x7dvfO"
      },
      "outputs": [],
      "source": [
        "# @title ## **4.3. Advanced Training Config** (Optional)\n",
        "import toml\n",
        "\n",
        "\n",
        "# @markdown ### **Optimizer State Config**\n",
        "save_optimizer_state      = False #@param {type:\"boolean\"}\n",
        "load_optimizer_state      = \"\" #@param {type:\"string\"}\n",
        "# @markdown ### **Noise Control**\n",
        "noise_control_type        = \"none\" #@param [\"none\", \"noise_offset\", \"multires_noise\"]\n",
        "# @markdown #### **a. Noise Offset**\n",
        "# @markdown Control and easily generating darker or light images by offset the noise when fine-tuning the model. Recommended value: `0.1`. Read [Diffusion With Offset Noise](https://www.crosslabs.org//blog/diffusion-with-offset-noise)\n",
        "noise_offset_num          = 0.0357  # @param {type:\"number\"}\n",
        "# @markdown **[Experimental]**\n",
        "# @markdown Automatically adjusts the noise offset based on the absolute mean values of each channel in the latents when used with `--noise_offset`. Specify a value around 1/10 to the same magnitude as the `--noise_offset` for best results. Set `0` to disable.\n",
        "adaptive_noise_scale      = 0.00357 # @param {type:\"number\"}\n",
        "# @markdown #### **b. Multires Noise**\n",
        "# @markdown enable multires noise with this number of iterations (if enabled, around 6-10 is recommended)\n",
        "multires_noise_iterations = 6 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "multires_noise_discount = 0.3 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n",
        "# @markdown ### **Caption Dropout**\n",
        "caption_dropout_rate = 0  # @param {type:\"number\"}\n",
        "caption_tag_dropout_rate = 0.5  # @param {type:\"number\"}\n",
        "caption_dropout_every_n_epochs = 0  # @param {type:\"number\"}\n",
        "# @markdown ### **Custom Train Function**\n",
        "# @markdown Gamma for reducing the weight of high-loss timesteps. Lower numbers have a stronger effect. The paper recommends `5`. Read the paper [here](https://arxiv.org/abs/2303.09556).\n",
        "min_snr_gamma             = 5 #@param {type:\"number\"}\n",
        "\n",
        "advanced_training_config = {\n",
        "    \"advanced_training_config\": {\n",
        "        \"resume\"                        : load_optimizer_state,\n",
        "        \"save_state\"                    : save_optimizer_state,\n",
        "        \"save_last_n_epochs_state\"      : save_optimizer_state,\n",
        "        \"noise_offset\"                  : noise_offset_num if noise_control_type == \"noise_offset\" else None,\n",
        "        \"adaptive_noise_scale\"          : adaptive_noise_scale if adaptive_noise_scale and noise_control_type == \"noise_offset\" else None,\n",
        "        \"multires_noise_iterations\"     : multires_noise_iterations if noise_control_type ==\"multires_noise\" else None,\n",
        "        \"multires_noise_discount\"       : multires_noise_discount if noise_control_type ==\"multires_noise\" else None,\n",
        "        \"caption_dropout_rate\"          : caption_dropout_rate,\n",
        "        \"caption_tag_dropout_rate\"      : caption_tag_dropout_rate,\n",
        "        \"caption_dropout_every_n_epochs\": caption_dropout_every_n_epochs,\n",
        "        \"min_snr_gamma\"                 : min_snr_gamma if not min_snr_gamma == -1 else None,\n",
        "    }\n",
        "}\n",
        "\n",
        "print(toml.dumps(advanced_training_config))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-Z4w3lfFKLjr",
        "cellView": "form",
        "outputId": "0a7a4e05-a2e8-44a5-b5ac-a2667bc8c5a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[sdxl_arguments]\n",
            "cache_text_encoder_outputs = true\n",
            "no_half_vae = true\n",
            "min_timestep = 0\n",
            "max_timestep = 1000\n",
            "shuffle_caption = false\n",
            "lowram = true\n",
            "\n",
            "[model_arguments]\n",
            "pretrained_model_name_or_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
            "vae = \"/content/vae/sdxl_vae.safetensors\"\n",
            "\n",
            "[dataset_arguments]\n",
            "debug_dataset = false\n",
            "in_json = \"/content/LoRA/meta_lat.json\"\n",
            "train_data_dir = \"/content/drive/MyDrive/Lora/train_data\"\n",
            "dataset_repeats = 3\n",
            "keep_tokens = 0\n",
            "resolution = \"1024,1024\"\n",
            "color_aug = false\n",
            "token_warmup_min = 1\n",
            "token_warmup_step = 0\n",
            "\n",
            "[training_arguments]\n",
            "output_dir = \"/content/drive/MyDrive/kohya-trainer/output/t1m_v4\"\n",
            "output_name = \"t1m_v4\"\n",
            "save_precision = \"fp16\"\n",
            "save_every_n_epochs = 1\n",
            "train_batch_size = 1\n",
            "max_token_length = 225\n",
            "mem_eff_attn = false\n",
            "sdpa = true\n",
            "xformers = false\n",
            "max_train_epochs = 50\n",
            "max_data_loader_n_workers = 8\n",
            "persistent_data_loader_workers = true\n",
            "gradient_checkpointing = true\n",
            "gradient_accumulation_steps = 1\n",
            "mixed_precision = \"fp16\"\n",
            "\n",
            "[logging_arguments]\n",
            "log_with = \"tensorboard\"\n",
            "logging_dir = \"/content/LoRA/logs\"\n",
            "log_prefix = \"t1m_v4\"\n",
            "\n",
            "[sample_prompt_arguments]\n",
            "sample_every_n_epochs = 1\n",
            "sample_sampler = \"euler_a\"\n",
            "\n",
            "[saving_arguments]\n",
            "save_model_as = \"safetensors\"\n",
            "\n",
            "[optimizer_arguments]\n",
            "optimizer_type = \"AdaFactor\"\n",
            "learning_rate = 0.0001\n",
            "max_grad_norm = 0\n",
            "optimizer_args = [ \"scale_parameter=False\", \"relative_step=False\", \"warmup_init=False\",]\n",
            "lr_scheduler = \"constant_with_warmup\"\n",
            "lr_warmup_steps = 100\n",
            "\n",
            "[additional_network_arguments]\n",
            "no_metadata = false\n",
            "network_module = \"networks.lora\"\n",
            "network_dim = 32\n",
            "network_alpha = 16\n",
            "network_args = []\n",
            "network_train_unet_only = true\n",
            "\n",
            "\u001b[38;2;204;102;102mWARNING: This is not an error message, but the [advanced_training_config]\n",
            "dictionary is missing. Please run the '4.2. Advanced Training Config' cell if\n",
            "you intend to use it, or continue to the next step.\u001b[0m\n",
            "\n",
            "[prompt]\n",
            "negative_prompt = \"3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\"\n",
            "width = 1024\n",
            "height = 1024\n",
            "scale = 12\n",
            "sample_steps = 28\n",
            "[[prompt.subset]]\n",
            "prompt = \"photo of a t1m man in a snowy forest wearing a red winter coat\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title ## **4.4. Training Config**\n",
        "import toml\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "\n",
        "%store -r\n",
        "\n",
        "# @markdown ### **Project Config**\n",
        "project_name                = \"t1m_v4\"  # @param {type:\"string\"}\n",
        "# @markdown Get your `wandb_api_key` [here](https://wandb.ai/settings) to logs with wandb.\n",
        "wandb_api_key               = \"\" # @param {type:\"string\"}\n",
        "in_json                     = \"/content/LoRA/meta_lat.json\"  # @param {type:\"string\"}\n",
        "# @markdown ### **SDXL Config**\n",
        "gradient_checkpointing      = True  # @param {type:\"boolean\"}\n",
        "no_half_vae                 = True  # @param {type:\"boolean\"}\n",
        "#@markdown Recommended parameter for SDXL training but if you enable it, `shuffle_caption` won't work\n",
        "cache_text_encoder_outputs  = True  # @param {type:\"boolean\"}\n",
        "#@markdown These options can be used to train U-Net with different timesteps. The default values are 0 and 1000.\n",
        "min_timestep                = 0 # @param {type:\"number\"}\n",
        "max_timestep                = 1000 # @param {type:\"number\"}\n",
        "# @markdown ### **Dataset Config**\n",
        "num_repeats                 = 3  # @param {type:\"number\"}\n",
        "resolution                  = 1024  # @param {type:\"slider\", min:512, max:1024, step:128}\n",
        "keep_tokens                 = 0  # @param {type:\"number\"}\n",
        "# @markdown ### **General Config**\n",
        "num_epochs                  = 50  # @param {type:\"number\"}\n",
        "train_batch_size            = 1  # @param {type:\"number\"}\n",
        "mixed_precision             = \"fp16\"  # @param [\"no\",\"fp16\",\"bf16\"] {allow-input: false}\n",
        "seed                        = -1  # @param {type:\"number\"}\n",
        "optimization                = \"scaled dot-product attention\" # @param [\"xformers\", \"scaled dot-product attention\"]\n",
        "# @markdown ### **Save Output Config**\n",
        "save_precision              = \"fp16\"  # @param [\"float\", \"fp16\", \"bf16\"] {allow-input: false}\n",
        "save_every_n_epochs         = 1  # @param {type:\"number\"}\n",
        "# @markdown ### **Sample Prompt Config**\n",
        "enable_sample               = True  # @param {type:\"boolean\"}\n",
        "sampler                     = \"euler_a\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "positive_prompt             = \"\"\n",
        "negative_prompt             = \"\"\n",
        "quality_prompt              = \"Stable Diffusion XL\"  # @param [\"None\", \"Waifu Diffusion 1.5\", \"NovelAI\", \"AbyssOrangeMix\", \"Stable Diffusion XL\"] {allow-input: false}\n",
        "if quality_prompt          == \"NovelAI\":\n",
        "    positive_prompt         = \"masterpiece, best quality, \"\n",
        "    negative_prompt         = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry, \"\n",
        "if quality_prompt          == \"AbyssOrangeMix\":\n",
        "    positive_prompt         = \"masterpiece, best quality, \"\n",
        "    negative_prompt         = \"(worst quality, low quality:1.4), \"\n",
        "if quality_prompt          == \"Stable Diffusion XL\":\n",
        "    negative_prompt         = \"3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\"\n",
        "custom_prompt               = \"photo of a t1m man in a snowy forest wearing a red winter coat\" # @param {type:\"string\"}\n",
        "# @markdown Specify `prompt_from_caption` if you want to use caption as prompt instead. Will be chosen randomly.\n",
        "prompt_from_caption         = \"none\"  # @param [\"none\", \".txt\", \".caption\"]\n",
        "if prompt_from_caption     != \"none\":\n",
        "    custom_prompt           = \"\"\n",
        "num_prompt                  = 2  # @param {type:\"number\"}\n",
        "logging_dir                 = os.path.join(training_dir, \"logs\")\n",
        "lowram                      = int(next(line.split()[1] for line in open('/proc/meminfo') if \"MemTotal\" in line)) / (1024**2) < 15\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "\n",
        "prompt_config = {\n",
        "    \"prompt\": {\n",
        "        \"negative_prompt\" : negative_prompt,\n",
        "        \"width\"           : resolution,\n",
        "        \"height\"          : resolution,\n",
        "        \"scale\"           : 12,\n",
        "        \"sample_steps\"    : 28,\n",
        "        \"subset\"          : [],\n",
        "    }\n",
        "}\n",
        "\n",
        "train_config = {\n",
        "    \"sdxl_arguments\": {\n",
        "        \"cache_text_encoder_outputs\" : cache_text_encoder_outputs,\n",
        "        \"no_half_vae\"                : True,\n",
        "        \"min_timestep\"               : min_timestep,\n",
        "        \"max_timestep\"               : max_timestep,\n",
        "        \"shuffle_caption\"            : True if not cache_text_encoder_outputs else False,\n",
        "        \"lowram\"                     : lowram\n",
        "    },\n",
        "    \"model_arguments\": {\n",
        "        \"pretrained_model_name_or_path\" : model_path,\n",
        "        \"vae\"                           : vae_path,\n",
        "    },\n",
        "    \"dataset_arguments\": {\n",
        "        \"debug_dataset\"                 : False,\n",
        "        \"in_json\"                       : in_json,\n",
        "        \"train_data_dir\"                : train_data_dir,\n",
        "        \"dataset_repeats\"               : num_repeats,\n",
        "        \"keep_tokens\"                   : keep_tokens,\n",
        "        \"resolution\"                    : str(resolution) + ',' + str(resolution),\n",
        "        \"color_aug\"                     : False,\n",
        "        \"face_crop_aug_range\"           : None,\n",
        "        \"token_warmup_min\"              : 1,\n",
        "        \"token_warmup_step\"             : 0,\n",
        "    },\n",
        "    \"training_arguments\": {\n",
        "        \"output_dir\"                    : os.path.join(output_dir, project_name),\n",
        "        \"output_name\"                   : project_name if project_name else \"last\",\n",
        "        \"save_precision\"                : save_precision,\n",
        "        \"save_every_n_epochs\"           : save_every_n_epochs,\n",
        "        \"save_n_epoch_ratio\"            : None,\n",
        "        \"save_last_n_epochs\"            : None,\n",
        "        \"resume\"                        : None,\n",
        "        \"train_batch_size\"              : train_batch_size,\n",
        "        \"max_token_length\"              : 225,\n",
        "        \"mem_eff_attn\"                  : False,\n",
        "        \"sdpa\"                          : True if optimization == \"scaled dot-product attention\" else False,\n",
        "        \"xformers\"                      : True if optimization == \"xformers\" else False,\n",
        "        \"max_train_epochs\"              : num_epochs,\n",
        "        \"max_data_loader_n_workers\"     : 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"seed\"                          : seed if seed > 0 else None,\n",
        "        \"gradient_checkpointing\"        : gradient_checkpointing,\n",
        "        \"gradient_accumulation_steps\"   : 1,\n",
        "        \"mixed_precision\"               : mixed_precision,\n",
        "    },\n",
        "    \"logging_arguments\": {\n",
        "        \"log_with\"          : \"wandb\" if wandb_api_key else \"tensorboard\",\n",
        "        \"log_tracker_name\"  : project_name if wandb_api_key and not project_name == \"last\" else None,\n",
        "        \"logging_dir\"       : logging_dir,\n",
        "        \"log_prefix\"        : project_name if not wandb_api_key else None,\n",
        "    },\n",
        "    \"sample_prompt_arguments\": {\n",
        "        \"sample_every_n_steps\"    : None,\n",
        "        \"sample_every_n_epochs\"   : save_every_n_epochs if enable_sample else None,\n",
        "        \"sample_sampler\"          : sampler,\n",
        "    },\n",
        "    \"saving_arguments\": {\n",
        "        \"save_model_as\": \"safetensors\"\n",
        "    },\n",
        "}\n",
        "\n",
        "def write_file(filename, contents):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(contents)\n",
        "\n",
        "def prompt_convert(enable_sample, num_prompt, train_data_dir, prompt_config, custom_prompt):\n",
        "    if enable_sample:\n",
        "        search_pattern = os.path.join(train_data_dir, '**/*' + prompt_from_caption)\n",
        "        caption_files = glob.glob(search_pattern, recursive=True)\n",
        "\n",
        "        if not caption_files:\n",
        "            if not custom_prompt:\n",
        "                custom_prompt = \"masterpiece, best quality, 1girl, aqua eyes, baseball cap, blonde hair, closed mouth, earrings, green background, hat, hoop earrings, jewelry, looking at viewer, shirt, short hair, simple background, solo, upper body, yellow shirt\"\n",
        "            new_prompt_config = prompt_config.copy()\n",
        "            new_prompt_config['prompt']['subset'] = [\n",
        "                {\"prompt\": positive_prompt + custom_prompt if positive_prompt else custom_prompt}\n",
        "            ]\n",
        "        else:\n",
        "            selected_files = random.sample(caption_files, min(num_prompt, len(caption_files)))\n",
        "\n",
        "            prompts = []\n",
        "            for file in selected_files:\n",
        "                with open(file, 'r') as f:\n",
        "                    prompts.append(f.read().strip())\n",
        "\n",
        "            new_prompt_config = prompt_config.copy()\n",
        "            new_prompt_config['prompt']['subset'] = []\n",
        "\n",
        "            for prompt in prompts:\n",
        "                new_prompt = {\n",
        "                    \"prompt\": positive_prompt + prompt if positive_prompt else prompt,\n",
        "                }\n",
        "                new_prompt_config['prompt']['subset'].append(new_prompt)\n",
        "\n",
        "        return new_prompt_config\n",
        "    else:\n",
        "        return prompt_config\n",
        "\n",
        "def eliminate_none_variable(config):\n",
        "    for key in config:\n",
        "        if isinstance(config[key], dict):\n",
        "            for sub_key in config[key]:\n",
        "                if config[key][sub_key] == \"\":\n",
        "                    config[key][sub_key] = None\n",
        "        elif config[key] == \"\":\n",
        "            config[key] = None\n",
        "\n",
        "    return config\n",
        "\n",
        "try:\n",
        "    train_config.update(optimizer_config)\n",
        "except NameError:\n",
        "    raise NameError(\"'optimizer_config' dictionary is missing. Please run  '4.1. Optimizer Config' cell.\")\n",
        "\n",
        "try:\n",
        "    train_config.update(lora_config)\n",
        "except NameError:\n",
        "    raise NameError(\"'lora_config' dictionary is missing. Please run  '4.1. LoRa: Low-Rank Adaptation Config' cell.\")\n",
        "\n",
        "advanced_training_warning = False\n",
        "try:\n",
        "    train_config.update(advanced_training_config)\n",
        "except NameError:\n",
        "    advanced_training_warning = True\n",
        "    pass\n",
        "\n",
        "prompt_config = prompt_convert(enable_sample, num_prompt, train_data_dir, prompt_config, custom_prompt)\n",
        "\n",
        "config_path         = os.path.join(config_dir, \"config_file.toml\")\n",
        "prompt_path         = os.path.join(config_dir, \"sample_prompt.toml\")\n",
        "\n",
        "config_str          = toml.dumps(eliminate_none_variable(train_config))\n",
        "prompt_str          = toml.dumps(eliminate_none_variable(prompt_config))\n",
        "\n",
        "write_file(config_path, config_str)\n",
        "write_file(prompt_path, prompt_str)\n",
        "\n",
        "print(config_str)\n",
        "\n",
        "if advanced_training_warning:\n",
        "    import textwrap\n",
        "    error_message = \"WARNING: This is not an error message, but the [advanced_training_config] dictionary is missing. Please run the '4.2. Advanced Training Config' cell if you intend to use it, or continue to the next step.\"\n",
        "    wrapped_message = textwrap.fill(error_message, width=80)\n",
        "    print('\\033[38;2;204;102;102m' + wrapped_message + '\\033[0m\\n')\n",
        "    pass\n",
        "\n",
        "print(prompt_str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_SHtbFwHVl1",
        "cellView": "form",
        "outputId": "68e18f38-b468-44ab-c9cc-5bc0f5708d69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading settings from /content/LoRA/config/config_file.toml...\n",
            "/content/LoRA/config/config_file\n",
            "prepare tokenizers\n",
            "update token length: 225\n",
            "Training with captions.\n",
            "loading existing metadata: /content/LoRA/meta_lat.json\n",
            "metadata has bucket info, enable bucketing / メタデータにbucket情報があるためbucketを有効にします\n",
            "using bucket info in metadata / メタデータ内のbucket情報を使います\n",
            "[Dataset 0]\n",
            "  batch_size: 1\n",
            "  resolution: (1024, 1024)\n",
            "  enable_bucket: True\n",
            "  min_bucket_reso: None\n",
            "  max_bucket_reso: None\n",
            "  bucket_reso_steps: None\n",
            "  bucket_no_upscale: None\n",
            "\n",
            "  [Subset 0 of Dataset 0]\n",
            "    image_dir: \"/content/drive/MyDrive/Lora/train_data\"\n",
            "    image_count: 15\n",
            "    num_repeats: 3\n",
            "    shuffle_caption: False\n",
            "    keep_tokens: 0\n",
            "    caption_dropout_rate: 0.0\n",
            "    caption_dropout_every_n_epoches: 0\n",
            "    caption_tag_dropout_rate: 0.0\n",
            "    color_aug: False\n",
            "    flip_aug: False\n",
            "    face_crop_aug_range: None\n",
            "    random_crop: False\n",
            "    token_warmup_min: 1,\n",
            "    token_warmup_step: 0,\n",
            "    metadata_file: /content/LoRA/meta_lat.json\n",
            "\n",
            "\n",
            "[Dataset 0]\n",
            "loading image sizes.\n",
            "100% 15/15 [00:00<00:00, 278383.01it/s]\n",
            "make buckets\n",
            "number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
            "bucket 0: resolution (320, 1024), count: 3\n",
            "bucket 1: resolution (384, 1024), count: 9\n",
            "bucket 2: resolution (768, 1024), count: 15\n",
            "bucket 3: resolution (1024, 1024), count: 18\n",
            "mean ar error (without repeats): 0.0\n",
            "noise_offset is set to 0.0357 / noise_offsetが0.0357に設定されました\n",
            "preparing accelerator\n",
            "loading model for process 0/1\n",
            "load Diffusers pretrained models: stabilityai/stable-diffusion-xl-base-1.0, variant=fp16\n",
            "Downloading (…)ain/model_index.json: 100% 609/609 [00:00<00:00, 3.15MB/s]\n",
            "Fetching 23 files:   0% 0/23 [00:00<?, ?it/s]\n",
            "Downloading (…)ncoder_2/config.json: 100% 575/575 [00:00<00:00, 2.74MB/s]\n",
            "\n",
            "Downloading (…)kenizer_2/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)_encoder/config.json: 100% 565/565 [00:00<00:00, 3.32MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)cial_tokens_map.json: 100% 460/460 [00:00<00:00, 2.40MB/s]\n",
            "\n",
            "\n",
            "Downloading (…)cheduler_config.json: 100% 479/479 [00:00<00:00, 3.29MB/s]\n",
            "Fetching 23 files:   9% 2/23 [00:01<00:12,  1.73it/s]\n",
            "Downloading (…)kenizer_2/merges.txt: 100% 525k/525k [00:00<00:00, 3.77MB/s]\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 725/725 [00:00<00:00, 5.02MB/s]\n",
            "\n",
            "Downloading (…)1d8/unet/config.json: 100% 1.68k/1.68k [00:00<00:00, 7.07MB/s]\n",
            "\n",
            "Downloading (…)kenizer_2/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)81d8/vae/config.json: 100% 642/642 [00:00<00:00, 3.59MB/s]\n",
            "\n",
            "Downloading (…)kenizer_2/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 5.26MB/s]\n",
            "\n",
            "Downloading model.fp16.safetensors:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading model.fp16.safetensors:   4% 10.5M/246M [00:00<00:02, 99.8MB/s]\u001b[A\n",
            "\n",
            "Downloading (…)/vae_1_0/config.json: 100% 607/607 [00:00<00:00, 141kB/s]\n",
            "\n",
            "Downloading model.fp16.safetensors:  13% 31.5M/246M [00:00<00:01, 143MB/s] \u001b[A\n",
            "Downloading model.fp16.safetensors:  26% 62.9M/246M [00:00<00:00, 203MB/s]\u001b[A\n",
            "\n",
            "Downloading model.onnx:   0% 0.00/1.04M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "Downloading model.onnx: 100% 1.04M/1.04M [00:00<00:00, 26.5MB/s]\n",
            "\n",
            "\n",
            "Downloading model.onnx:   0% 0.00/493M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   0% 0.00/1.39G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  51% 126M/246M [00:00<00:00, 211MB/s] \u001b[A\n",
            "\n",
            "Downloading model.onnx:   2% 10.5M/493M [00:00<00:09, 48.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:   0% 0.00/198M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   1% 10.5M/1.39G [00:00<00:38, 35.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   0% 0.00/5.14G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:   4% 21.0M/493M [00:00<00:08, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:   0% 0.00/7.29M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  11% 21.0M/198M [00:00<00:01, 99.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   2% 21.0M/1.39G [00:00<00:28, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:   6% 31.5M/493M [00:00<00:07, 63.4MB/s]\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  64% 157M/246M [00:01<00:00, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   0% 10.5M/5.14G [00:00<01:55, 44.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  16% 31.5M/198M [00:00<00:02, 80.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   2% 31.5M/1.39G [00:00<00:23, 58.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:   9% 41.9M/493M [00:00<00:06, 71.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 7.29M/7.29M [00:00<00:00, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 10.5M/167M [00:00<00:01, 86.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  21% 41.9M/198M [00:01<00:09, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx: 100% 7.29M/7.29M [00:04<00:00, 1.79MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:   0% 0.00/137M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   3% 41.9M/1.39G [00:04<03:49, 5.87MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:   8% 10.5M/137M [00:00<00:02, 44.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 21.0M/167M [00:04<00:30, 4.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   0% 21.0M/5.14G [00:04<22:00, 3.87MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 21.0M/167M [00:04<00:35, 4.12MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  26% 52.4M/198M [00:04<00:20, 7.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  15% 21.0M/137M [00:00<00:01, 59.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  72% 178M/246M [00:05<00:04, 15.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 31.5M/167M [00:04<00:19, 6.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  13% 62.9M/493M [00:05<00:53, 7.98MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  32% 62.9M/198M [00:05<00:14, 9.58MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   4% 52.4M/1.39G [00:05<02:54, 7.65MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  15% 73.4M/493M [00:05<00:37, 11.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 31.5M/167M [00:04<00:19, 6.85MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  23% 31.5M/137M [00:00<00:03, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  37% 73.4M/198M [00:05<00:09, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   5% 62.9M/1.39G [00:05<02:05, 10.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  25% 41.9M/167M [00:05<00:12, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   1% 31.5M/5.14G [00:05<14:57, 5.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  25% 41.9M/167M [00:05<00:14, 8.77MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  42% 83.9M/198M [00:05<00:07, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  17% 83.9M/493M [00:06<00:31, 12.9MB/s]\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  81% 199M/246M [00:06<00:02, 17.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  31% 52.4M/167M [00:05<00:09, 12.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  31% 41.9M/137M [00:01<00:04, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   5% 73.4M/1.39G [00:06<01:44, 12.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  31% 52.4M/167M [00:05<00:09, 12.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   1% 41.9M/5.14G [00:06<10:42, 7.93MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  48% 94.4M/198M [00:06<00:05, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  19% 94.4M/493M [00:06<00:25, 15.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  38% 62.9M/167M [00:05<00:06, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  85% 210M/246M [00:07<00:01, 18.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   6% 83.9M/1.39G [00:06<01:21, 15.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  38% 52.4M/137M [00:01<00:03, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  38% 62.9M/167M [00:05<00:06, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   1% 52.4M/5.14G [00:06<07:43, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  21% 105M/493M [00:06<00:20, 19.1MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  53% 105M/198M [00:06<00:04, 21.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  44% 73.4M/167M [00:06<00:04, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   7% 94.4M/1.39G [00:06<01:09, 18.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  46% 62.9M/137M [00:02<00:02, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  89% 220M/246M [00:07<00:01, 19.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  44% 73.4M/167M [00:06<00:05, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  58% 115M/198M [00:06<00:03, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  23% 115M/493M [00:07<00:17, 21.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   1% 62.9M/5.14G [00:06<06:11, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   8% 105M/1.39G [00:07<00:57, 22.3MB/s] \u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  94% 231M/246M [00:07<00:00, 22.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  54% 73.4M/137M [00:02<00:02, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  50% 83.9M/167M [00:06<00:03, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  50% 83.9M/167M [00:06<00:03, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  26% 126M/493M [00:07<00:14, 24.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  64% 126M/198M [00:07<00:02, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   1% 73.4M/5.14G [00:07<05:04, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   8% 115M/1.39G [00:07<00:51, 24.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors:  98% 241M/246M [00:08<00:00, 23.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  61% 83.9M/137M [00:02<00:01, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  56% 94.4M/167M [00:06<00:03, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  28% 136M/493M [00:07<00:13, 26.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  56% 94.4M/167M [00:07<00:03, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Downloading model.fp16.safetensors: 100% 246M/246M [00:08<00:00, 24.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  69% 136M/198M [00:07<00:02, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   2% 83.9M/5.14G [00:07<04:12, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:   9% 126M/1.39G [00:07<00:47, 26.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors: 100% 246M/246M [00:08<00:00, 29.4MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fetching 23 files:  17% 4/23 [00:09<00:53,  2.82s/it]\n",
            "\n",
            "Downloading model.onnx:  30% 147M/493M [00:07<00:11, 29.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  74% 147M/198M [00:07<00:01, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  10% 136M/1.39G [00:07<00:37, 33.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  63% 105M/167M [00:07<00:02, 26.2MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   2% 94.4M/5.14G [00:07<03:34, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  77% 105M/137M [00:03<00:00, 34.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  69% 115M/167M [00:07<00:01, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  79% 157M/198M [00:07<00:01, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  69% 115M/167M [00:07<00:01, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  11% 147M/1.39G [00:08<00:33, 37.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  32% 157M/493M [00:08<00:10, 33.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   2% 105M/5.14G [00:07<02:51, 29.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  84% 115M/137M [00:03<00:00, 35.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  75% 126M/167M [00:07<00:01, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  75% 126M/167M [00:07<00:01, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  92% 126M/137M [00:03<00:00, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  11% 157M/1.39G [00:08<00:41, 29.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  85% 168M/198M [00:08<00:01, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  81% 136M/167M [00:08<00:01, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  34% 168M/493M [00:08<00:12, 25.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   2% 115M/5.14G [00:08<03:33, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  81% 136M/167M [00:08<00:01, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 136M/137M [00:04<00:00, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  12% 168M/1.39G [00:09<01:05, 18.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  88% 147M/167M [00:09<00:01, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 137M/137M [00:05<00:00, 26.8MB/s]\n",
            "\n",
            "\n",
            "Downloading model.onnx:  36% 178M/493M [00:09<00:18, 17.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  88% 147M/167M [00:09<00:01, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  90% 178M/198M [00:09<00:01, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  13% 178M/1.39G [00:09<00:55, 21.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  94% 157M/167M [00:09<00:00, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   3% 136M/5.14G [00:09<04:00, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  38% 189M/493M [00:10<00:14, 21.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx:  95% 189M/198M [00:09<00:00, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  14% 189M/1.39G [00:10<00:46, 25.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  94% 157M/167M [00:09<00:00, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors: 100% 167M/167M [00:09<00:00, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  40% 199M/493M [00:10<00:11, 25.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   3% 147M/5.14G [00:09<03:25, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 198M/198M [00:10<00:00, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors: 100% 167M/167M [00:09<00:00, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 198M/198M [00:10<00:00, 19.1MB/s]\n",
            "Downloading (…)del.fp16.safetensors: 100% 167M/167M [00:10<00:00, 16.7MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors: 100% 167M/167M [00:10<00:00, 16.6MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  15% 210M/1.39G [00:10<00:37, 31.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  43% 210M/493M [00:10<00:11, 24.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   3% 168M/5.14G [00:10<02:37, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  16% 220M/1.39G [00:10<00:31, 37.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  45% 220M/493M [00:10<00:09, 29.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   3% 178M/5.14G [00:10<02:09, 38.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  17% 231M/1.39G [00:11<00:25, 46.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  47% 231M/493M [00:11<00:07, 35.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  17% 241M/1.39G [00:11<00:20, 54.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   4% 189M/5.14G [00:10<02:05, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  18% 252M/1.39G [00:11<00:19, 57.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  49% 241M/493M [00:11<00:06, 39.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   4% 199M/5.14G [00:10<01:42, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  19% 262M/1.39G [00:11<00:18, 61.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  51% 252M/493M [00:12<00:11, 20.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   4% 210M/5.14G [00:13<06:34, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  20% 273M/1.39G [00:14<01:55, 9.65MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  53% 262M/493M [00:14<00:23, 9.96MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   4% 220M/5.14G [00:14<07:10, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  20% 283M/1.39G [00:14<01:26, 12.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   4% 231M/5.14G [00:14<05:42, 14.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  55% 273M/493M [00:15<00:17, 12.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  21% 294M/1.39G [00:15<01:06, 16.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   5% 241M/5.14G [00:14<04:24, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  60% 294M/493M [00:15<00:09, 21.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  22% 304M/1.39G [00:15<00:50, 21.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  23% 315M/1.39G [00:15<00:38, 28.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  62% 304M/493M [00:15<00:07, 26.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   5% 252M/5.14G [00:14<03:24, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   5% 262M/5.14G [00:15<02:38, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  64% 315M/493M [00:15<00:05, 30.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   5% 273M/5.14G [00:15<02:13, 36.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  68% 336M/493M [00:15<00:03, 45.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  24% 336M/1.39G [00:15<00:29, 35.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 294M/5.14G [00:15<01:29, 53.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  72% 357M/493M [00:15<00:02, 58.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  26% 357M/1.39G [00:15<00:20, 50.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  77% 377M/493M [00:16<00:01, 73.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  27% 377M/1.39G [00:15<00:15, 66.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 304M/5.14G [00:15<01:40, 48.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  81% 398M/493M [00:16<00:01, 85.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  29% 398M/1.39G [00:16<00:12, 78.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 315M/5.14G [00:15<01:30, 53.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   6% 325M/5.14G [00:15<01:19, 60.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  30% 419M/1.39G [00:16<00:10, 91.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  32% 440M/1.39G [00:16<00:08, 109MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   7% 346M/5.14G [00:16<01:01, 77.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  85% 419M/493M [00:16<00:01, 72.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  33% 461M/1.39G [00:16<00:08, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  87% 430M/493M [00:16<00:00, 76.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   7% 367M/5.14G [00:16<00:57, 83.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  89% 440M/493M [00:16<00:00, 77.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   7% 377M/5.14G [00:16<00:56, 84.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  35% 482M/1.39G [00:16<00:08, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  92% 451M/493M [00:16<00:00, 76.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   8% 388M/5.14G [00:16<00:56, 84.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  94% 461M/493M [00:17<00:00, 79.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   8% 398M/5.14G [00:16<00:57, 81.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  36% 503M/1.39G [00:17<00:08, 98.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  96% 472M/493M [00:17<00:00, 80.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   8% 409M/5.14G [00:16<00:58, 81.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx:  98% 482M/493M [00:17<00:00, 83.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   8% 419M/5.14G [00:16<00:55, 84.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  38% 524M/1.39G [00:17<00:09, 92.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Downloading model.onnx: 100% 493M/493M [00:17<00:00, 80.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading model.onnx: 100% 493M/493M [00:17<00:00, 28.1MB/s]\n",
            "Fetching 23 files:  22% 5/23 [00:19<01:27,  4.84s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   9% 440M/5.14G [00:17<00:55, 84.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  39% 545M/1.39G [00:17<00:09, 91.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   9% 461M/5.14G [00:17<00:45, 104MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  41% 566M/1.39G [00:17<00:08, 100MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:   9% 482M/5.14G [00:17<00:41, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  42% 587M/1.39G [00:17<00:07, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  10% 503M/5.14G [00:17<00:39, 116MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  44% 608M/1.39G [00:18<00:07, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  10% 524M/5.14G [00:17<00:39, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  45% 629M/1.39G [00:18<00:06, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  11% 545M/5.14G [00:18<00:38, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  47% 650M/1.39G [00:18<00:06, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  11% 566M/5.14G [00:18<00:37, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  48% 671M/1.39G [00:18<00:05, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  11% 587M/5.14G [00:18<00:36, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  50% 692M/1.39G [00:18<00:05, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  12% 608M/5.14G [00:18<00:36, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  51% 713M/1.39G [00:18<00:05, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  12% 629M/5.14G [00:18<00:35, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  53% 734M/1.39G [00:19<00:05, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 650M/5.14G [00:18<00:36, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  54% 755M/1.39G [00:19<00:05, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 671M/5.14G [00:19<00:36, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  56% 776M/1.39G [00:19<00:04, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  13% 692M/5.14G [00:19<00:34, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  57% 797M/1.39G [00:19<00:04, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  14% 713M/5.14G [00:19<00:45, 96.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  59% 818M/1.39G [00:19<00:06, 91.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  14% 734M/5.14G [00:19<00:39, 111MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  15% 755M/5.14G [00:19<00:37, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  60% 839M/1.39G [00:20<00:05, 92.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  15% 776M/5.14G [00:19<00:33, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  61% 849M/1.39G [00:20<00:06, 89.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  62% 860M/1.39G [00:20<00:06, 87.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  16% 797M/5.14G [00:20<00:38, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  63% 881M/1.39G [00:20<00:04, 108MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  16% 818M/5.14G [00:20<00:34, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  65% 902M/1.39G [00:20<00:04, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  16% 839M/5.14G [00:20<00:30, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  17% 860M/5.14G [00:20<00:35, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  66% 923M/1.39G [00:21<00:05, 93.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  67% 933M/1.39G [00:21<00:05, 87.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  17% 881M/5.14G [00:20<00:41, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  68% 944M/1.39G [00:21<00:05, 76.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  69% 954M/1.39G [00:21<00:05, 78.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  18% 902M/5.14G [00:21<00:46, 91.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  69% 965M/1.39G [00:21<00:05, 83.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  70% 975M/1.39G [00:21<00:05, 80.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  18% 923M/5.14G [00:21<00:46, 89.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  71% 986M/1.39G [00:21<00:05, 76.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  72% 996M/1.39G [00:22<00:05, 76.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  18% 933M/5.14G [00:21<01:04, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  18% 944M/5.14G [00:23<02:52, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  73% 1.02G/1.39G [00:23<00:15, 23.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  74% 1.03G/1.39G [00:24<00:18, 19.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 954M/5.14G [00:24<03:36, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  75% 1.05G/1.39G [00:24<00:11, 29.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 975M/5.14G [00:24<02:24, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  77% 1.07G/1.39G [00:24<00:07, 40.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  19% 996M/5.14G [00:24<01:44, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  78% 1.09G/1.39G [00:25<00:05, 52.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  20% 1.02G/5.14G [00:24<01:21, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  80% 1.11G/1.39G [00:25<00:04, 64.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  20% 1.04G/5.14G [00:24<01:05, 62.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  82% 1.13G/1.39G [00:25<00:03, 76.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  21% 1.06G/5.14G [00:25<00:54, 74.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  83% 1.15G/1.39G [00:25<00:02, 86.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  21% 1.08G/5.14G [00:25<00:47, 86.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  85% 1.17G/1.39G [00:25<00:02, 97.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  21% 1.10G/5.14G [00:25<00:41, 97.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  86% 1.20G/1.39G [00:26<00:02, 91.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  22% 1.12G/5.14G [00:25<00:49, 81.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  88% 1.22G/1.39G [00:26<00:01, 94.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  22% 1.13G/5.14G [00:25<00:49, 80.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  89% 1.24G/1.39G [00:26<00:01, 109MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  22% 1.14G/5.14G [00:26<00:47, 84.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  91% 1.26G/1.39G [00:27<00:03, 37.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  91% 1.27G/1.39G [00:27<00:02, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  23% 1.16G/5.14G [00:27<02:15, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  23% 1.17G/5.14G [00:27<01:56, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  93% 1.29G/1.39G [00:28<00:01, 55.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  94% 1.31G/1.39G [00:28<00:01, 69.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  23% 1.20G/5.14G [00:27<01:24, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  23% 1.21G/5.14G [00:27<01:15, 51.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  96% 1.33G/1.39G [00:28<00:00, 78.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  24% 1.23G/5.14G [00:28<00:56, 68.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  97% 1.35G/1.39G [00:28<00:00, 88.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  24% 1.25G/5.14G [00:29<01:50, 35.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  25% 1.26G/5.14G [00:29<01:35, 40.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors:  99% 1.37G/1.39G [00:29<00:00, 39.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  25% 1.28G/5.14G [00:29<01:10, 55.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Downloading model.fp16.safetensors: 100% 1.39G/1.39G [00:29<00:00, 46.4MB/s]\n",
            "Fetching 23 files:  30% 7/23 [00:32<01:27,  5.48s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  25% 1.30G/5.14G [00:29<01:04, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  26% 1.32G/5.14G [00:29<00:49, 77.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  26% 1.35G/5.14G [00:30<00:35, 107MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  27% 1.37G/5.14G [00:30<00:31, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  27% 1.39G/5.14G [00:30<00:27, 136MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  28% 1.42G/5.14G [00:30<00:25, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  28% 1.44G/5.14G [00:30<00:23, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  29% 1.47G/5.14G [00:30<00:20, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  29% 1.49G/5.14G [00:30<00:19, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  29% 1.51G/5.14G [00:30<00:21, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  30% 1.53G/5.14G [00:30<00:20, 179MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  30% 1.56G/5.14G [00:31<00:18, 189MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  31% 1.58G/5.14G [00:31<00:18, 193MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  31% 1.60G/5.14G [00:31<00:27, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  32% 1.63G/5.14G [00:31<00:24, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  32% 1.66G/5.14G [00:31<00:19, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  33% 1.68G/5.14G [00:31<00:19, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  33% 1.70G/5.14G [00:31<00:19, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  33% 1.72G/5.14G [00:32<00:23, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  34% 1.74G/5.14G [00:32<00:30, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  34% 1.76G/5.14G [00:32<00:29, 116MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  35% 1.78G/5.14G [00:32<00:30, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  35% 1.80G/5.14G [00:33<00:32, 104MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  36% 1.82G/5.14G [00:33<00:32, 100MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  36% 1.85G/5.14G [00:33<00:30, 108MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  36% 1.87G/5.14G [00:34<00:58, 55.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  37% 1.89G/5.14G [00:34<00:50, 64.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  37% 1.91G/5.14G [00:34<00:39, 80.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  38% 1.93G/5.14G [00:34<00:33, 96.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  38% 1.96G/5.14G [00:34<00:24, 128MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  39% 1.98G/5.14G [00:34<00:22, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  39% 2.00G/5.14G [00:35<00:21, 143MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  40% 2.03G/5.14G [00:35<00:18, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  40% 2.07G/5.14G [00:35<00:17, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  41% 2.10G/5.14G [00:35<00:15, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  41% 2.12G/5.14G [00:35<00:15, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  42% 2.15G/5.14G [00:35<00:14, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  42% 2.18G/5.14G [00:35<00:14, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  43% 2.21G/5.14G [00:36<00:14, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  43% 2.23G/5.14G [00:36<00:14, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  44% 2.25G/5.14G [00:36<00:13, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  44% 2.28G/5.14G [00:36<00:14, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  45% 2.30G/5.14G [00:36<00:13, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  45% 2.33G/5.14G [00:36<00:13, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  46% 2.35G/5.14G [00:36<00:13, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  46% 2.37G/5.14G [00:36<00:13, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  47% 2.39G/5.14G [00:37<00:29, 94.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  47% 2.41G/5.14G [00:37<00:29, 93.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  48% 2.44G/5.14G [00:37<00:22, 121MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  48% 2.47G/5.14G [00:37<00:17, 148MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  49% 2.50G/5.14G [00:37<00:16, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  49% 2.52G/5.14G [00:38<00:15, 167MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  49% 2.54G/5.14G [00:38<00:15, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  50% 2.57G/5.14G [00:38<00:13, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  51% 2.60G/5.14G [00:38<00:12, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  51% 2.62G/5.14G [00:38<00:12, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  51% 2.64G/5.14G [00:38<00:12, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  52% 2.67G/5.14G [00:38<00:12, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  52% 2.69G/5.14G [00:38<00:12, 198MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  53% 2.72G/5.14G [00:39<00:12, 198MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  53% 2.74G/5.14G [00:39<00:12, 192MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  54% 2.76G/5.14G [00:39<00:13, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  54% 2.79G/5.14G [00:39<00:11, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  55% 2.82G/5.14G [00:39<00:10, 215MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  56% 2.85G/5.14G [00:39<00:11, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  56% 2.88G/5.14G [00:39<00:11, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  57% 2.90G/5.14G [00:39<00:11, 199MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  57% 2.93G/5.14G [00:40<00:11, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  58% 2.96G/5.14G [00:40<00:10, 201MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  58% 2.98G/5.14G [00:40<00:10, 202MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  59% 3.01G/5.14G [00:40<00:10, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  59% 3.03G/5.14G [00:40<00:10, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  59% 3.05G/5.14G [00:40<00:10, 194MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  60% 3.07G/5.14G [00:40<00:10, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  60% 3.09G/5.14G [00:40<00:10, 196MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  61% 3.11G/5.14G [00:41<00:10, 195MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  61% 3.14G/5.14G [00:44<01:36, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  62% 3.17G/5.14G [00:44<01:03, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  62% 3.19G/5.14G [00:44<00:53, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  62% 3.21G/5.14G [00:44<00:42, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  63% 3.23G/5.14G [00:45<00:36, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  63% 3.25G/5.14G [00:45<00:30, 61.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  64% 3.27G/5.14G [00:45<00:27, 68.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  64% 3.29G/5.14G [00:45<00:26, 68.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  65% 3.31G/5.14G [00:46<00:24, 73.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  65% 3.32G/5.14G [00:46<00:24, 73.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  65% 3.33G/5.14G [00:46<00:24, 73.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  65% 3.34G/5.14G [00:46<00:25, 69.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  65% 3.36G/5.14G [00:46<00:24, 73.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  66% 3.37G/5.14G [00:46<00:23, 74.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  66% 3.38G/5.14G [00:46<00:23, 73.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  66% 3.39G/5.14G [00:47<00:24, 72.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  66% 3.41G/5.14G [00:47<00:19, 88.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  67% 3.42G/5.14G [00:47<00:20, 82.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  67% 3.44G/5.14G [00:47<00:16, 106MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  67% 3.46G/5.14G [00:47<00:13, 126MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  68% 3.48G/5.14G [00:47<00:11, 140MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  68% 3.50G/5.14G [00:47<00:10, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  69% 3.52G/5.14G [00:49<00:39, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  69% 3.54G/5.14G [00:49<00:33, 47.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  70% 3.58G/5.14G [00:49<00:22, 70.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  70% 3.60G/5.14G [00:49<00:17, 86.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  70% 3.62G/5.14G [00:49<00:14, 104MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  71% 3.64G/5.14G [00:49<00:12, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  71% 3.66G/5.14G [00:50<00:11, 133MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  72% 3.68G/5.14G [00:50<00:10, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  72% 3.70G/5.14G [00:50<00:09, 154MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  73% 3.73G/5.14G [00:50<00:08, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  73% 3.76G/5.14G [00:50<00:07, 189MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  74% 3.80G/5.14G [00:50<00:06, 200MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  75% 3.83G/5.14G [00:50<00:06, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  75% 3.86G/5.14G [00:51<00:05, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  76% 3.89G/5.14G [00:51<00:05, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  76% 3.92G/5.14G [00:51<00:05, 213MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  77% 3.95G/5.14G [00:51<00:05, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  78% 3.98G/5.14G [00:51<00:05, 204MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  78% 4.01G/5.14G [00:51<00:05, 197MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  79% 4.04G/5.14G [00:51<00:05, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  79% 4.06G/5.14G [00:51<00:05, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  79% 4.08G/5.14G [00:52<00:05, 204MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  80% 4.10G/5.14G [00:54<00:32, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  80% 4.12G/5.14G [00:54<00:24, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  81% 4.14G/5.14G [00:54<00:19, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  81% 4.17G/5.14G [00:54<00:13, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  82% 4.20G/5.14G [00:54<00:09, 93.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  82% 4.23G/5.14G [00:54<00:08, 106MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  83% 4.25G/5.14G [00:55<00:07, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  83% 4.27G/5.14G [00:55<00:06, 130MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  84% 4.30G/5.14G [00:55<00:05, 154MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  84% 4.33G/5.14G [00:55<00:04, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  85% 4.36G/5.14G [00:55<00:04, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  85% 4.38G/5.14G [00:55<00:04, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  86% 4.40G/5.14G [00:55<00:03, 191MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  86% 4.42G/5.14G [00:55<00:03, 194MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  87% 4.46G/5.14G [00:56<00:03, 202MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  87% 4.49G/5.14G [00:56<00:03, 204MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  88% 4.51G/5.14G [00:56<00:03, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  88% 4.54G/5.14G [00:56<00:02, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  89% 4.57G/5.14G [00:56<00:02, 208MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  89% 4.59G/5.14G [00:59<00:18, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  90% 4.62G/5.14G [00:59<00:12, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  90% 4.65G/5.14G [00:59<00:10, 45.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  91% 4.67G/5.14G [00:59<00:08, 56.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  91% 4.69G/5.14G [01:00<00:07, 63.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  92% 4.71G/5.14G [01:00<00:05, 75.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  92% 4.73G/5.14G [01:00<00:04, 87.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  93% 4.75G/5.14G [01:00<00:03, 100MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  93% 4.77G/5.14G [01:00<00:03, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  93% 4.79G/5.14G [01:00<00:02, 131MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  94% 4.81G/5.14G [01:00<00:02, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  94% 4.84G/5.14G [01:00<00:01, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  95% 4.87G/5.14G [01:02<00:06, 44.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  95% 4.89G/5.14G [01:03<00:08, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  95% 4.90G/5.14G [01:03<00:07, 32.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  96% 4.92G/5.14G [01:04<00:05, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  96% 4.94G/5.14G [01:04<00:03, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  97% 4.96G/5.14G [01:04<00:02, 68.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  97% 4.98G/5.14G [01:04<00:01, 84.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  98% 5.01G/5.14G [01:04<00:01, 75.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  98% 5.04G/5.14G [01:05<00:00, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  99% 5.08G/5.14G [01:05<00:00, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors:  99% 5.10G/5.14G [01:05<00:00, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Downloading (…)del.fp16.safetensors: 100% 5.14G/5.14G [01:05<00:00, 78.3MB/s]\n",
            "Fetching 23 files: 100% 23/23 [01:08<00:00,  2.96s/it]\n",
            "The config attributes {'add_watermarker': None} were passed to StableDiffusionXLPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
            "Keyword arguments {'add_watermarker': None} are not expected by StableDiffusionXLPipeline and will be ignored.\n",
            "The config attributes {'force_upcast': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
            "U-Net converted to original U-Net\n",
            "load VAE: /content/vae/sdxl_vae.safetensors\n",
            "additional VAE loaded\n",
            "Enable SDPA for U-Net\n",
            "import network module: networks.lora\n",
            "[Dataset 0]\n",
            "caching text encoder outputs.\n",
            "checking cache existence...\n",
            "100% 15/15 [00:00<00:00, 298173.27it/s]\n",
            "caching text encoder outputs...\n",
            "100% 15/15 [00:01<00:00,  8.61it/s]\n",
            "create LoRA network. base dim (rank): 32, alpha: 16\n",
            "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
            "create LoRA for Text Encoder 1:\n",
            "create LoRA for Text Encoder 2:\n",
            "create LoRA for Text Encoder: 264 modules.\n",
            "create LoRA for U-Net: 722 modules.\n",
            "enable LoRA for U-Net\n",
            "prepare optimizer, data loader etc.\n",
            "use Adafactor optimizer | {'scale_parameter': False, 'relative_step': False, 'warmup_init': False}\n",
            "override steps. steps for 50 epochs is / 指定エポックまでのステップ数: 2250\n",
            "running training / 学習開始\n",
            "  num train images * repeats / 学習画像の数×繰り返し回数: 45\n",
            "  num reg images / 正則化画像の数: 0\n",
            "  num batches per epoch / 1epochのバッチ数: 45\n",
            "  num epochs / epoch数: 50\n",
            "  batch size per device / バッチサイズ: 1\n",
            "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
            "  total optimization steps / 学習ステップ数: 2250\n",
            "steps:   0% 0/2250 [00:00<?, ?it/s]\n",
            "epoch 1/50\n",
            "steps:   2% 45/2250 [01:49<1:29:48,  2.44s/it, loss=0.0984]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/t1m_v4/t1m_v4-000001.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 45\n",
            "prompt: photo of a t1m man in a snowy forest wearing a red winter coat\n",
            "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:33,  1.25s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:31,  1.20s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:29,  1.19s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:28,  1.18s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:27,  1.18s/it]\u001b[A\n",
            " 21% 6/28 [00:07<00:26,  1.18s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.19s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.19s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.19s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.20s/it]\u001b[A\n",
            " 39% 11/28 [00:13<00:20,  1.20s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:19,  1.20s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:18,  1.21s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.21s/it]\u001b[A\n",
            " 54% 15/28 [00:18<00:15,  1.22s/it]\u001b[A\n",
            " 57% 16/28 [00:19<00:14,  1.22s/it]\u001b[A\n",
            " 61% 17/28 [00:20<00:13,  1.22s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:12,  1.22s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:11,  1.23s/it]\u001b[A\n",
            " 71% 20/28 [00:24<00:09,  1.23s/it]\u001b[A\n",
            " 75% 21/28 [00:25<00:08,  1.23s/it]\u001b[A\n",
            " 79% 22/28 [00:26<00:07,  1.22s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:06,  1.22s/it]\u001b[A\n",
            " 86% 24/28 [00:29<00:04,  1.22s/it]\u001b[A\n",
            " 89% 25/28 [00:30<00:03,  1.22s/it]\u001b[A\n",
            " 93% 26/28 [00:31<00:02,  1.22s/it]\u001b[A\n",
            " 96% 27/28 [00:32<00:01,  1.21s/it]\u001b[A\n",
            "100% 28/28 [00:33<00:00,  1.21s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 2/50\n",
            "steps:   4% 90/2250 [04:24<1:45:57,  2.94s/it, loss=0.0954]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/t1m_v4/t1m_v4-000002.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 90\n",
            "prompt: photo of a t1m man in a snowy forest wearing a red winter coat\n",
            "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:31,  1.18s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:30,  1.16s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:29,  1.16s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:27,  1.16s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:26,  1.16s/it]\u001b[A\n",
            " 21% 6/28 [00:06<00:25,  1.16s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.16s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.17s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.17s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.17s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:20,  1.18s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:18,  1.18s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.19s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.19s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.19s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.20s/it]\u001b[A\n",
            " 61% 17/28 [00:20<00:13,  1.21s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:12,  1.21s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.21s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.22s/it]\u001b[A\n",
            " 75% 21/28 [00:24<00:08,  1.22s/it]\u001b[A\n",
            " 79% 22/28 [00:26<00:07,  1.22s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:06,  1.22s/it]\u001b[A\n",
            " 86% 24/28 [00:28<00:04,  1.22s/it]\u001b[A\n",
            " 89% 25/28 [00:29<00:03,  1.21s/it]\u001b[A\n",
            " 93% 26/28 [00:31<00:02,  1.21s/it]\u001b[A\n",
            " 96% 27/28 [00:32<00:01,  1.21s/it]\u001b[A\n",
            "100% 28/28 [00:33<00:00,  1.20s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 3/50\n",
            "steps:   6% 135/2250 [06:55<1:48:22,  3.07s/it, loss=0.107]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/t1m_v4/t1m_v4-000003.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 135\n",
            "prompt: photo of a t1m man in a snowy forest wearing a red winter coat\n",
            "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:31,  1.18s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:37,  1.46s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:32,  1.32s/it]\u001b[A\n",
            " 14% 4/28 [00:05<00:30,  1.25s/it]\u001b[A\n",
            " 18% 5/28 [00:06<00:27,  1.22s/it]\u001b[A\n",
            " 21% 6/28 [00:07<00:26,  1.20s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.19s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.18s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.18s/it]\u001b[A\n",
            " 36% 10/28 [00:12<00:21,  1.18s/it]\u001b[A\n",
            " 39% 11/28 [00:13<00:20,  1.18s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:18,  1.18s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.18s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.19s/it]\u001b[A\n",
            " 54% 15/28 [00:18<00:15,  1.19s/it]\u001b[A\n",
            " 57% 16/28 [00:19<00:14,  1.20s/it]\u001b[A\n",
            " 61% 17/28 [00:20<00:13,  1.20s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:12,  1.21s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.21s/it]\u001b[A\n",
            " 71% 20/28 [00:24<00:09,  1.22s/it]\u001b[A\n",
            " 75% 21/28 [00:25<00:08,  1.22s/it]\u001b[A\n",
            " 79% 22/28 [00:26<00:07,  1.22s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:06,  1.22s/it]\u001b[A\n",
            " 86% 24/28 [00:29<00:04,  1.22s/it]\u001b[A\n",
            " 89% 25/28 [00:30<00:03,  1.22s/it]\u001b[A\n",
            " 93% 26/28 [00:31<00:02,  1.22s/it]\u001b[A\n",
            " 96% 27/28 [00:32<00:01,  1.22s/it]\u001b[A\n",
            "100% 28/28 [00:33<00:00,  1.21s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 4/50\n",
            "steps:   8% 180/2250 [09:29<1:49:07,  3.16s/it, loss=0.0922]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/t1m_v4/t1m_v4-000004.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 180\n",
            "prompt: photo of a t1m man in a snowy forest wearing a red winter coat\n",
            "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:32,  1.19s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:30,  1.16s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:28,  1.15s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:27,  1.15s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:26,  1.15s/it]\u001b[A\n",
            " 21% 6/28 [00:06<00:25,  1.15s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.15s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.16s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.16s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:20,  1.16s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:19,  1.17s/it]\u001b[A\n",
            " 43% 12/28 [00:13<00:18,  1.17s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.17s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.18s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.18s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.19s/it]\u001b[A\n",
            " 61% 17/28 [00:19<00:13,  1.19s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:11,  1.20s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.20s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.21s/it]\u001b[A\n",
            " 75% 21/28 [00:24<00:08,  1.22s/it]\u001b[A\n",
            " 79% 22/28 [00:26<00:07,  1.22s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:06,  1.22s/it]\u001b[A\n",
            " 86% 24/28 [00:28<00:04,  1.22s/it]\u001b[A\n",
            " 89% 25/28 [00:29<00:03,  1.22s/it]\u001b[A\n",
            " 93% 26/28 [00:30<00:02,  1.22s/it]\u001b[A\n",
            " 96% 27/28 [00:32<00:01,  1.22s/it]\u001b[A\n",
            "100% 28/28 [00:33<00:00,  1.22s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 5/50\n",
            "steps:  10% 225/2250 [12:03<1:48:27,  3.21s/it, loss=0.0765]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/t1m_v4/t1m_v4-000005.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 225\n",
            "prompt: photo of a t1m man in a snowy forest wearing a red winter coat\n",
            "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:32,  1.20s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:30,  1.17s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:29,  1.16s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:27,  1.16s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:26,  1.16s/it]\u001b[A\n",
            " 21% 6/28 [00:06<00:25,  1.16s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.16s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.17s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.17s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.17s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:19,  1.17s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:18,  1.18s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.18s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.19s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.19s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.19s/it]\u001b[A\n",
            " 61% 17/28 [00:20<00:13,  1.20s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:12,  1.20s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.21s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.21s/it]\u001b[A\n",
            " 75% 21/28 [00:24<00:08,  1.21s/it]\u001b[A\n",
            " 79% 22/28 [00:26<00:07,  1.21s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:06,  1.21s/it]\u001b[A\n",
            " 86% 24/28 [00:28<00:04,  1.21s/it]\u001b[A\n",
            " 89% 25/28 [00:29<00:03,  1.21s/it]\u001b[A\n",
            " 93% 26/28 [00:30<00:02,  1.20s/it]\u001b[A\n",
            " 96% 27/28 [00:32<00:01,  1.20s/it]\u001b[A\n",
            "100% 28/28 [00:33<00:00,  1.20s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 6/50\n",
            "steps:  12% 270/2250 [14:34<1:46:50,  3.24s/it, loss=0.1]  \n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/t1m_v4/t1m_v4-000006.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 270\n",
            "prompt: photo of a t1m man in a snowy forest wearing a red winter coat\n",
            "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:31,  1.17s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:30,  1.15s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:28,  1.15s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:27,  1.15s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:26,  1.15s/it]\u001b[A\n",
            " 21% 6/28 [00:06<00:25,  1.15s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.16s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.16s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.16s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.17s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:19,  1.17s/it]\u001b[A\n",
            " 43% 12/28 [00:13<00:18,  1.18s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.18s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.18s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.19s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.19s/it]\u001b[A\n",
            " 61% 17/28 [00:19<00:13,  1.20s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:12,  1.20s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.21s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.21s/it]\u001b[A\n",
            " 75% 21/28 [00:24<00:08,  1.22s/it]\u001b[A\n",
            " 79% 22/28 [00:26<00:07,  1.22s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:06,  1.22s/it]\u001b[A\n",
            " 86% 24/28 [00:28<00:04,  1.22s/it]\u001b[A\n",
            " 89% 25/28 [00:29<00:03,  1.22s/it]\u001b[A\n",
            " 93% 26/28 [00:30<00:02,  1.22s/it]\u001b[A\n",
            " 96% 27/28 [00:32<00:01,  1.22s/it]\u001b[A\n",
            "100% 28/28 [00:33<00:00,  1.21s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 7/50\n",
            "steps:  14% 315/2250 [17:06<1:45:03,  3.26s/it, loss=0.0658]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/t1m_v4/t1m_v4-000007.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 315\n",
            "prompt: photo of a t1m man in a snowy forest wearing a red winter coat\n",
            "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:31,  1.17s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:30,  1.16s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:28,  1.16s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:27,  1.16s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:26,  1.16s/it]\u001b[A\n",
            " 21% 6/28 [00:06<00:25,  1.16s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.16s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.17s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.17s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.17s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:19,  1.17s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:18,  1.18s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.18s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.19s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.19s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.19s/it]\u001b[A\n",
            " 61% 17/28 [00:20<00:13,  1.20s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:12,  1.20s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.20s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.21s/it]\u001b[A\n",
            " 75% 21/28 [00:24<00:08,  1.21s/it]\u001b[A\n",
            " 79% 22/28 [00:26<00:07,  1.21s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:06,  1.21s/it]\u001b[A\n",
            " 86% 24/28 [00:28<00:04,  1.21s/it]\u001b[A\n",
            " 89% 25/28 [00:29<00:03,  1.21s/it]\u001b[A\n",
            " 93% 26/28 [00:30<00:02,  1.21s/it]\u001b[A\n",
            " 96% 27/28 [00:32<00:01,  1.21s/it]\u001b[A\n",
            "100% 28/28 [00:33<00:00,  1.20s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 8/50\n",
            "steps:  16% 360/2250 [19:39<1:43:11,  3.28s/it, loss=0.0946]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/t1m_v4/t1m_v4-000008.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 360\n",
            "prompt: photo of a t1m man in a snowy forest wearing a red winter coat\n",
            "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:32,  1.20s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:30,  1.17s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:29,  1.16s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:27,  1.16s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:26,  1.16s/it]\u001b[A\n",
            " 21% 6/28 [00:06<00:25,  1.16s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.16s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.16s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.17s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.17s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:19,  1.17s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:18,  1.18s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.18s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.18s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.19s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.19s/it]\u001b[A\n",
            " 61% 17/28 [00:20<00:13,  1.20s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:12,  1.20s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.21s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.21s/it]\u001b[A\n",
            " 75% 21/28 [00:24<00:08,  1.21s/it]\u001b[A\n",
            " 79% 22/28 [00:26<00:07,  1.21s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:06,  1.21s/it]\u001b[A\n",
            " 86% 24/28 [00:28<00:04,  1.21s/it]\u001b[A\n",
            " 89% 25/28 [00:29<00:03,  1.21s/it]\u001b[A\n",
            " 93% 26/28 [00:30<00:02,  1.21s/it]\u001b[A\n",
            " 96% 27/28 [00:32<00:01,  1.21s/it]\u001b[A\n",
            "100% 28/28 [00:33<00:00,  1.21s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 9/50\n",
            "steps:  18% 405/2250 [22:07<1:40:48,  3.28s/it, loss=0.0886]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/t1m_v4/t1m_v4-000009.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 405\n",
            "prompt: photo of a t1m man in a snowy forest wearing a red winter coat\n",
            "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:32,  1.20s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:30,  1.17s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:29,  1.16s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:27,  1.16s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:26,  1.16s/it]\u001b[A\n",
            " 21% 6/28 [00:06<00:25,  1.16s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.16s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.16s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.17s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.17s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:19,  1.18s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:18,  1.18s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.18s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.19s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.19s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.19s/it]\u001b[A\n",
            " 61% 17/28 [00:20<00:13,  1.20s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:12,  1.20s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.21s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.21s/it]\u001b[A\n",
            " 75% 21/28 [00:24<00:08,  1.22s/it]\u001b[A\n",
            " 79% 22/28 [00:26<00:07,  1.22s/it]\u001b[A\n",
            " 82% 23/28 [00:27<00:06,  1.22s/it]\u001b[A\n",
            " 86% 24/28 [00:28<00:04,  1.22s/it]\u001b[A\n",
            " 89% 25/28 [00:29<00:03,  1.22s/it]\u001b[A\n",
            " 93% 26/28 [00:31<00:02,  1.22s/it]\u001b[A\n",
            " 96% 27/28 [00:32<00:01,  1.21s/it]\u001b[A\n",
            "100% 28/28 [00:33<00:00,  1.21s/it]\u001b[A\n",
            "                                   \u001b[A\n",
            "epoch 10/50\n",
            "steps:  20% 450/2250 [24:41<1:38:47,  3.29s/it, loss=0.0666]\n",
            "saving checkpoint: /content/drive/MyDrive/kohya-trainer/output/t1m_v4/t1m_v4-000010.safetensors\n",
            "\n",
            "generating sample images at step / サンプル画像生成 ステップ: 450\n",
            "prompt: photo of a t1m man in a snowy forest wearing a red winter coat\n",
            "negative_prompt: 3d render, smooth, plastic, blurry, grainy, low-resolution, deep-fried, oversaturated\n",
            "height: 1024\n",
            "width: 1024\n",
            "sample_steps: 28\n",
            "scale: 12\n",
            "\n",
            "  0% 0/28 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/28 [00:01<00:31,  1.18s/it]\u001b[A\n",
            "  7% 2/28 [00:02<00:30,  1.16s/it]\u001b[A\n",
            " 11% 3/28 [00:03<00:29,  1.16s/it]\u001b[A\n",
            " 14% 4/28 [00:04<00:27,  1.16s/it]\u001b[A\n",
            " 18% 5/28 [00:05<00:26,  1.16s/it]\u001b[A\n",
            " 21% 6/28 [00:06<00:25,  1.16s/it]\u001b[A\n",
            " 25% 7/28 [00:08<00:24,  1.16s/it]\u001b[A\n",
            " 29% 8/28 [00:09<00:23,  1.17s/it]\u001b[A\n",
            " 32% 9/28 [00:10<00:22,  1.17s/it]\u001b[A\n",
            " 36% 10/28 [00:11<00:21,  1.17s/it]\u001b[A\n",
            " 39% 11/28 [00:12<00:19,  1.17s/it]\u001b[A\n",
            " 43% 12/28 [00:14<00:18,  1.18s/it]\u001b[A\n",
            " 46% 13/28 [00:15<00:17,  1.18s/it]\u001b[A\n",
            " 50% 14/28 [00:16<00:16,  1.19s/it]\u001b[A\n",
            " 54% 15/28 [00:17<00:15,  1.19s/it]\u001b[A\n",
            " 57% 16/28 [00:18<00:14,  1.19s/it]\u001b[A\n",
            " 61% 17/28 [00:20<00:13,  1.20s/it]\u001b[A\n",
            " 64% 18/28 [00:21<00:12,  1.20s/it]\u001b[A\n",
            " 68% 19/28 [00:22<00:10,  1.21s/it]\u001b[A\n",
            " 71% 20/28 [00:23<00:09,  1.21s/it]\u001b[A"
          ]
        }
      ],
      "source": [
        "#@title ## **4.5. Start Training**\n",
        "import os\n",
        "import toml\n",
        "\n",
        "#@markdown Check your config here if you want to edit something:\n",
        "#@markdown - `sample_prompt` : /content/LoRA/config/sample_prompt.toml\n",
        "#@markdown - `config_file` : /content/LoRA/config/config_file.toml\n",
        "\n",
        "\n",
        "#@markdown You can import config from another session if you want.\n",
        "\n",
        "sample_prompt   = \"/content/LoRA/config/sample_prompt.toml\" #@param {type:'string'}\n",
        "config_file     = \"/content/LoRA/config/config_file.toml\" #@param {type:'string'}\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        contents = f.read()\n",
        "    return contents\n",
        "\n",
        "def train(config):\n",
        "    args = \"\"\n",
        "    for k, v in config.items():\n",
        "        if k.startswith(\"_\"):\n",
        "            args += f'\"{v}\" '\n",
        "        elif isinstance(v, str):\n",
        "            args += f'--{k}=\"{v}\" '\n",
        "        elif isinstance(v, bool) and v:\n",
        "            args += f\"--{k} \"\n",
        "        elif isinstance(v, float) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "        elif isinstance(v, int) and not isinstance(v, bool):\n",
        "            args += f\"--{k}={v} \"\n",
        "\n",
        "    return args\n",
        "\n",
        "accelerate_conf = {\n",
        "    \"config_file\" : \"/content/kohya-trainer/accelerate_config/config.yaml\",\n",
        "    \"num_cpu_threads_per_process\" : 1,\n",
        "}\n",
        "\n",
        "train_conf = {\n",
        "    \"sample_prompts\"  : sample_prompt if os.path.exists(sample_prompt) else None,\n",
        "    \"config_file\"     : config_file,\n",
        "    \"wandb_api_key\"   : wandb_api_key if wandb_api_key else None\n",
        "}\n",
        "\n",
        "accelerate_args = train(accelerate_conf)\n",
        "train_args = train(train_conf)\n",
        "\n",
        "final_args = f\"accelerate launch {accelerate_args} sdxl_train_network.py {train_args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vhtDOMtG7qd"
      },
      "source": [
        "## V. Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t4OhkX7Dz7CH"
      },
      "outputs": [],
      "source": [
        "#@title ## **5.1. Inference**\n",
        "\n",
        "import os\n",
        "%store -r\n",
        "\n",
        "# @markdown ### Model Config\n",
        "network_weights = \"\" #@param {type:'string'}\n",
        "network_mul = 0.7 # @param {type:\"slider\", min:-1, max:1, step:0.05}\n",
        "# @markdown ### Prompt Config\n",
        "prompt = \"face focus, cute, 1girl, green hair, sweater, looking at viewer, upper body, beanie, outdoors, night, turtleneck\" #@param {type:'string'}\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry\" #@param {type:'string'}\n",
        "output_path = \"/content/tmp/\" #@param {type:'string'}\n",
        "resolution = \"1024, 1024\" # @param {type: \"string\"}\n",
        "optimization = \"scaled dot-product attention\" # @param [\"xformers\", \"scaled dot-product attention\"]\n",
        "conditional_resolution = \"1024, 1024\" # @param {type: \"string\"}\n",
        "steps = 28 # @param {type: \"number\"}\n",
        "sampler = \"euler_a\"  # @param [\"ddim\", \"pndm\", \"lms\", \"euler\", \"euler_a\", \"heun\", \"dpm_2\", \"dpm_2_a\", \"dpmsolver\",\"dpmsolver++\", \"dpmsingle\", \"k_lms\", \"k_euler\", \"k_euler_a\", \"k_dpm_2\", \"k_dpm_2_a\"]\n",
        "scale = 7 # @param {type: \"number\"}\n",
        "seed = -1 # @param {type: \"number\"}\n",
        "images_per_prompt = 1 # @param {type: \"number\"}\n",
        "batch_size = 1 # @param {type: \"number\"}\n",
        "clip_skip = 2 # @param {type: \"number\"}\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "separators = [\"*\", \"x\", \",\"]\n",
        "\n",
        "for separator in separators:\n",
        "    if separator in resolution:\n",
        "        width, height = [value.strip() for value in resolution.split(separator)]\n",
        "        original_width, original_height = [value.strip() for value in conditional_resolution.split(separator)]\n",
        "        break\n",
        "\n",
        "network_config = {\n",
        "    \"network_module\": network_module,\n",
        "    \"network_weights\": network_weights,\n",
        "    \"network_show_meta\": True,\n",
        "    \"network_mul\": network_mul,\n",
        "}\n",
        "\n",
        "config = {\n",
        "    \"prompt\": prompt + \" --n \" + negative_prompt,\n",
        "    \"images_per_prompt\": images_per_prompt,\n",
        "    \"outdir\": output_path,\n",
        "    \"W\": width,\n",
        "    \"H\": height,\n",
        "    \"original_width\": original_width,\n",
        "    \"original_height\": original_height,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"vae_batch_size\": 1,\n",
        "    \"no_half_vae\": True,\n",
        "    \"steps\": steps,\n",
        "    \"sampler\": sampler,\n",
        "    \"scale\": scale,\n",
        "    \"ckpt\": model_path,\n",
        "    \"vae\": vae_path,\n",
        "    \"seed\": seed if seed > 0 else None,\n",
        "    \"fp16\": True,\n",
        "    \"sdpa\": True if optimization == \"scaled dot-product attention\" else False,\n",
        "    \"xformers\": True if optimization == \"xformers\" else False,\n",
        "    \"opt_channels_last\": True,\n",
        "    \"clip_skip\": clip_skip,\n",
        "    \"max_embeddings_multiples\": 3,\n",
        "}\n",
        "\n",
        "if network_weights != \"\":\n",
        "    config.update(network_config)\n",
        "\n",
        "args = \"\"\n",
        "for k, v in config.items():\n",
        "    if k.startswith(\"_\"):\n",
        "        args += f'\"{v}\" '\n",
        "    elif isinstance(v, str):\n",
        "        args += f'--{k}=\"{v}\" '\n",
        "    elif isinstance(v, bool) and v:\n",
        "        args += f\"--{k} \"\n",
        "    elif isinstance(v, float) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "    elif isinstance(v, int) and not isinstance(v, bool):\n",
        "        args += f\"--{k}={v} \"\n",
        "\n",
        "final_args = f\"python sdxl_gen_img.py {args}\"\n",
        "\n",
        "os.chdir(repo_dir)\n",
        "!{final_args}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyIl9BhNXKUq"
      },
      "source": [
        "# **VI. Deployment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8YlP0cNQyujy"
      },
      "outputs": [],
      "source": [
        "# @title ## **6.1. Huggingface Hub config**\n",
        "from huggingface_hub import login\n",
        "from huggingface_hub import HfApi\n",
        "from huggingface_hub.utils import validate_repo_id, HfHubHTTPError\n",
        "\n",
        "# @markdown Login to Huggingface Hub\n",
        "# @markdown > Get **your** huggingface `WRITE` token [here](https://huggingface.co/settings/tokens)\n",
        "write_token = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Fill this if you want to upload to your organization, or just leave it empty.\n",
        "orgs_name = \"\"  # @param{type:\"string\"}\n",
        "# @markdown If your model/dataset repo does not exist, it will automatically create it.\n",
        "model_name = \"sdxl-model\"  # @param{type:\"string\"}\n",
        "dataset_name = \"sdxl-dataset\"  # @param{type:\"string\"}\n",
        "make_private = True  # @param{type:\"boolean\"}\n",
        "\n",
        "def authenticate(write_token):\n",
        "    login(write_token, add_to_git_credential=True)\n",
        "    api = HfApi()\n",
        "    return api.whoami(write_token), api\n",
        "\n",
        "def create_repo(api, user, orgs_name, repo_name, repo_type, make_private=False):\n",
        "    global model_repo\n",
        "    global datasets_repo\n",
        "\n",
        "    if orgs_name == \"\":\n",
        "        repo_id = user[\"name\"] + \"/\" + repo_name.strip()\n",
        "    else:\n",
        "        repo_id = orgs_name + \"/\" + repo_name.strip()\n",
        "\n",
        "    try:\n",
        "        validate_repo_id(repo_id)\n",
        "        api.create_repo(repo_id=repo_id, repo_type=repo_type, private=make_private)\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' didn't exist, creating repo\")\n",
        "    except HfHubHTTPError as e:\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' exists, skipping create repo\")\n",
        "\n",
        "    if repo_type == \"model\":\n",
        "        model_repo = repo_id\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/{repo_id}\\n\")\n",
        "    else:\n",
        "        datasets_repo = repo_id\n",
        "        print(f\"{repo_type.capitalize()} repo '{repo_id}' link: https://huggingface.co/datasets/{repo_id}\\n\")\n",
        "\n",
        "user, api = authenticate(write_token)\n",
        "\n",
        "if model_name:\n",
        "    create_repo(api, user, orgs_name, model_name, \"model\", make_private)\n",
        "if dataset_name:\n",
        "    create_repo(api, user, orgs_name, dataset_name, \"dataset\", make_private)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8HpOZOglBJTz"
      },
      "outputs": [],
      "source": [
        "# @title ## **6.2. Upload LoRA to Huggingface**\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "\n",
        "%store -r\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# @markdown This will be uploaded to model repo\n",
        "model_path = \"/content/LoRA/output/\"  # @param {type :\"string\"}\n",
        "path_in_repo = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown Now you can save your config file for future use\n",
        "config_path = \"/content/LoRA/config\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown Other Information\n",
        "commit_message = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "    commit_message = f\"feat: upload {project_name} lora model\"\n",
        "\n",
        "def upload_to_hf(model_path, is_folder, is_config):\n",
        "    path_obj = Path(model_path)\n",
        "    trained_model = path_obj.parts[-1]\n",
        "\n",
        "    if path_in_repo:\n",
        "        trained_model = path_in_repo\n",
        "\n",
        "    if is_config:\n",
        "        trained_model = f\"{project_name}_config\"\n",
        "\n",
        "    print(f\"Uploading {trained_model} to https://huggingface.co/{model_repo}\")\n",
        "    print(\"Please wait...\")\n",
        "\n",
        "    if is_folder:\n",
        "        api.upload_folder(\n",
        "            folder_path=model_path,\n",
        "            path_in_repo=trained_model,\n",
        "            repo_id=model_repo,\n",
        "            commit_message=commit_message,\n",
        "            ignore_patterns=\".ipynb_checkpoints\",\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/{model_repo}/tree/main\\n\")\n",
        "    else:\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=model_path,\n",
        "            path_in_repo=trained_model,\n",
        "            repo_id=model_repo,\n",
        "            commit_message=commit_message,\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/{model_repo}/blob/main/{trained_model}\\n\")\n",
        "\n",
        "def upload():\n",
        "    is_model_file = model_path.endswith((\".ckpt\", \".safetensors\", \".pt\"))\n",
        "    upload_to_hf(model_path, not is_model_file, False)\n",
        "\n",
        "    if config_path:\n",
        "        upload_to_hf(config_path, True, True)\n",
        "\n",
        "upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IW-hS9jnmf-E"
      },
      "outputs": [],
      "source": [
        "# @title ## **6.3. Upload Dataset to Huggingface**\n",
        "from huggingface_hub import HfApi\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# @markdown This will be compressed to zip and  uploaded to datasets repo, leave it empty if not necessary\n",
        "train_data_path = \"/content/LoRA/train_data\"  # @param {type :\"string\"}\n",
        "\n",
        "# @markdown `Nerd stuff, only if you want to save training logs`\n",
        "logs_path = \"/content/LoRA/logs\"  # @param {type :\"string\"}\n",
        "\n",
        "tmp_dataset = f\"/content/LoRA/{project_name}_dataset\" if project_name else \"/content/LoRA/tmp_dataset\"\n",
        "tmp_train_data = f\"{tmp_dataset}/train_data\"\n",
        "dataset_zip = f\"{tmp_dataset}.zip\"\n",
        "\n",
        "# @markdown Other Information\n",
        "commit_message = \"\"  # @param {type :\"string\"}\n",
        "\n",
        "if not commit_message:\n",
        "    commit_message = f\"feat: upload {project_name} dataset and logs\"\n",
        "\n",
        "os.makedirs(tmp_dataset, exist_ok=True)\n",
        "os.makedirs(tmp_train_data, exist_ok=True)\n",
        "\n",
        "def upload_dataset(dataset_path, is_zip):\n",
        "    path_obj = Path(dataset_path)\n",
        "    dataset_name = path_obj.parts[-1]\n",
        "\n",
        "    print(f\"Uploading {dataset_name} to https://huggingface.co/datasets/{datasets_repo}\")\n",
        "    print(\"Please wait...\")\n",
        "\n",
        "    if is_zip:\n",
        "        api.upload_file(\n",
        "            path_or_fileobj=dataset_path,\n",
        "            path_in_repo=dataset_name,\n",
        "            repo_id=datasets_repo,\n",
        "            repo_type=\"dataset\",\n",
        "            commit_message=commit_message,\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/datasets/{datasets_repo}/blob/main/{dataset_name}\\n\")\n",
        "    else:\n",
        "        api.upload_folder(\n",
        "            folder_path=dataset_path,\n",
        "            path_in_repo=dataset_name,\n",
        "            repo_id=datasets_repo,\n",
        "            repo_type=\"dataset\",\n",
        "            commit_message=commit_message,\n",
        "            ignore_patterns=\".ipynb_checkpoints\",\n",
        "        )\n",
        "        print(f\"Upload success, located at https://huggingface.co/datasets/{datasets_repo}/tree/main/{dataset_name}\\n\")\n",
        "\n",
        "def zip_file(folder_path):\n",
        "    zip_path = f\"{folder_path}.zip\"\n",
        "    with zipfile.ZipFile(zip_path, \"w\") as zip_file:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                zip_file.write(os.path.join(root, file))\n",
        "\n",
        "def move(src_path, dst_path, move_metadata):\n",
        "    metadata_files = [\n",
        "        \"meta_cap.json\",\n",
        "        \"meta_cap_dd.json\",\n",
        "        \"meta_lat.json\",\n",
        "        \"meta_clean.json\",\n",
        "        \"meta_final.json\",\n",
        "    ]\n",
        "\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.move(src_path, dst_path)\n",
        "\n",
        "    if move_metadata:\n",
        "        parent_meta_path = os.path.dirname(src_path)\n",
        "\n",
        "        for filename in os.listdir(parent_meta_path):\n",
        "            file_path = os.path.join(parent_meta_path, filename)\n",
        "            if filename in metadata_files:\n",
        "                shutil.move(file_path, dst_path)\n",
        "\n",
        "def upload():\n",
        "    if train_data_path:\n",
        "        move(train_data_path, tmp_train_data, False)\n",
        "        zip_file(tmp_dataset)\n",
        "        upload_dataset(dataset_zip, True)\n",
        "        os.remove(dataset_zip)\n",
        "    if logs_path:\n",
        "        upload_dataset(logs_path, False)\n",
        "\n",
        "upload()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}